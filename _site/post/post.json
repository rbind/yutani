[
  {
    "path": "post/2021-06-14-unofficial-introduction-to-extendr-2-type-conversion-between-r-and-rust/",
    "title": "Unofficial Introduction To extendr (2): Type Conversion Between R and Rust",
    "description": "Integrate R and Rust with extendr",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2021-06-14",
    "categories": [
      "Rust",
      "extendr"
    ],
    "contents": "\n\nContents\nVector\nNA\nPrimitive types\nlist\nRobj?\nWhat’s next?\n\nextendr is a project that provides an interface between R and Rust. In the last post, I explained about how to create an R package with extendr briefly. This time, we’ll walk though how to handle various R types.\nVector\nLet’s start with the last example in the last post.\n\n#[extendr]\nfn add(x: i32, y: i32) -> i32 {\n    x + y\n}\n\nWhile this works perfectly fine with a single value, this fails when the length is more than one.\n\n\nadd(1:2, 2:3)\n\n\nError in add(1:2, 2:3): Input must be of length 1. Vector of length >1 given.\n\nThis is very easy to fix. In Rust, we can use Vec<T> to represent a vector of values of type T.\n\n// I don't explain much about the Rust code this time, but, for now, please don't\n// worry if you can't understand what it does at the moment. Probably it's not\n// very important to understand this post. Move forward.\n\n#[extendr]\nfn add2(x: Vec<i32>, y: Vec<i32>) -> Vec<i32> {\n    x.iter().enumerate().map(|(i, x)| x + y[i]).collect()\n}\n\n\n\nadd2(1:2, 2:3)\n\n\n[1] 3 5\n\nEasy!\nWait, didn’t you say we can’t do this…!?\nSome of you might remember, in this post, I wrote\n\nWe cannot simply pass a variable length of vector\n\nfrom R to Rust.\nYeah, it’s true it was too difficult because I was struggling to do it via FFI! There’s no metadata available about the length or the structure of the data by default. But, with extendr, we can seamlessly access these metadata via R’s C API. So, in short, extendr is the game changer.\n&[T]\nIf you are already familiar with Rust, you might feel using Vec<T> as arguments looks a bit weird. In fact, the document of Vec<T> says:\n\nIn Rust, it’s more common to pass slices as arguments rather than vectors when you just want to provide read access. The same goes for String and &str.\n(https://doc.rust-lang.org/std/vec/struct.Vec.html#slicing)\n\nYes, you can use &[T] instead of Vec<T>, and this seems to matter on the performance slightly. If you are familiar with Rust to the extent that you know the difference between &[T] and Vec<T> (confession: I’m not!), you can should use &[T] instead. Otherwise, Vec<T> just works.\n\n#[extendr]\nfn add2_slice(x: &[i32], y: &[i32]) -> Vec<i32> {\n    x.iter().enumerate().map(|(i, x)| x + y[i]).collect()\n}\n\n\n\nadd2_slice(1:2, 2:3)\n\n\n[1] 3 5\n\nPlease note that this isn’t the reference to the original R object, just that to the copied values. If you really want no copying, you should use the “proxy” types, which I’ll cover in the next post.\nNA\nOne more caveat about add() is that this cannot handle a missing value, NA.\n\n\nadd(1L, NA)\n\n\nError in add(1L, NA): unable to convert R object to primitive\n\nIn Rust, we can use Option<T> to represent an optional, or possibly missing, value.\n\n// pattern match is one of the most powerful things in Rust, btw!\n\n#[extendr]\nfn add3(x: Option<i32>, y: Option<i32>) -> Option<i32> {\n    match (x, y) {\n        (Some(x), Some(y)) => Some(x + y),\n        _ => NA_INTEGER\n    }\n}\n\nThis function can handle NA.\n\n\nadd3(1L, 2L)\n\n\n[1] 3\n\nadd3(1L, NA)\n\n\n[1] NA\n\nIt might be safe to always use Option since there’s always possibility that R value can be NA by nature. But, we might want to choose non-Option version to avoid the overhead (c.f. How much overhead is there with Options and Results? - The Rust Programming Language Forum), so it depends.\nPrimitive types\nOkay, let’s learn about the primitive types at last. Here’s the corresponding table of R types and Rust types. We don’t have the direct equivalent of factor and complex here, but let’s talk about it later.\nR\nRust\ninteger\ni32\nnumeric\nf64\nlogical\nbool\nc haracter\nS tring &str\nfactor\n-\ncomplex\n-\ninteger and numeric\ninteger and numeric can mainly be converted into i32 and f64 respectively. I used “mainly” because it’s not that strict. They both can be converted into either of:\nu8\nu16\nu32\nu64\ni8\ni16\ni32\ni64\nf32\nf64\nSo, in other words, if you don’t want to prevent from numeric values are coerced into integers, you’ll need to check the types by yourself.\nlogical\nlogical is translated from/into bool. That’s all.\ncharacter\ncharacter is a bit tricky in that you can convert it to either of String and &str. You’ll probably have to scratch your head to understand the concept of “lifetime” to choose the proper one (confession: I still don’t understand it). But, in short,\nString : choose this when you modify the content strings\n&str: choose this (probably with 'static lifetime) when you only reference the strings\nIf you are not familiar with Rust yet, I recommend you to start with String. String is copied around so you might have unnecessary overhead, but it’s generally easier to handle because we need to think about the lifetimes less frequently.\nfactor\nTo put things simpler, until this point, I deliberately chose the cases when we have the corresponding types in Rust’s side. But, factor isn’t the case. It cannot be directly converted into a simple Rust type (at least at the moment). Instead, it can be cast into StrItr. StrItr is a “proxy” to the underlying data on R’s side.\nI’ll try explaining this in another post, but keep in mind that extendr provides that “proxy”-type of interface as well as the simple conversion to Rust’s primitive types.\nlist\nA list can be converted into HashMap<String, Robj>. Robj is also a “proxy,” which contains arbitrary R data.\n\n#[extendr]\nfn print_a(x: HashMap<String, Robj>) {\n    println!(\"{:?}\", x.get(\"a\"));\n}\n\n\n\nprint_a(list(a = 1, b = 2))\nprint_a(list(b = 2))\n\n\n\nr! is a macro to create an R object from a Rust expression, by the way.\nRobj?\nAs a sneak peak of the next post, let’s take a look at the usage of Robj.\nSo far, I created only functions that accepts just one type. What if we want to create a function that accepts multiple types of arguments? In this case, we can create a function that takes Robj as its argument and convert it by ourselves. Robj has many methods as_XXX() to convert to (or, more precisely, extract and copy the value of R object, and turn it into) a type. Here, let’s use as_integer() to generate Option<i32> .\n\n#[extendr]\nfn int(x: Robj) -> Option<i32> {\n    x.as_integer()\n}\n\n\n\n# integer\nint(1L)\n\n\n[1] 1\n\n# not integer-ish\nint(\"foo\")\n\n\n[1] NA\n\nWhat’s next?\nIn this post, I focused mainly the Rust’s side of the type ecosystem. Next, I probably need to write about more R-ish things like Function or Symbol , which I need some time to understand correctly. Stay tuned…\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-19T09:35:42+09:00",
    "input_file": "unofficial-introduction-to-extendr-2-type-conversion-between-r-and-rust.knit.md"
  },
  {
    "path": "post/2021-06-07-gghighlight-032/",
    "title": "gghighlight 0.3.2",
    "description": "",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2021-06-07",
    "categories": [
      "gghighlight",
      "ggplot2",
      "package"
    ],
    "contents": "\n\nContents\nn()\nTo unhighlight or not to unhighlight…\n\ngghighlight 0.3.2 is on CRAN now!\nThis release is mainly for fixing the potential test failures with upcoming version of ggplot2, but this version contains two new features.\nn()\nSince gghighlight uses dplyr inside, you can now use dplyr’s expression, n(). This is useful to highlight based on the size of the group.\nSuppose we have this data:\n\n\nlibrary(gghighlight)\nlibrary(dplyr, warn.conflicts = FALSE)\n\nset.seed(1098)\ncenters <- tibble(\n  id = sample(letters, 11),\n  x = c(-1, -2, -3,   0,  1,  4,  2,  5,  7,  1, -1),\n  y = c( 4, -3, -7, -10, -8, -3,  9,  5, -1,  1, -1),\n  n = c(50, 50, 100, 50, 50, 120, 40, 10, 20, 5, 8)\n)\n\nd <- centers %>% \n  rowwise() %>% \n  summarise(id = id, x = x + rnorm(n, sd = 3), y = y + rnorm(n, sd = 3))\n\np <- ggplot(d, aes(x, y, colour = id)) + geom_point()\np\n\n\n\n\nBy using n(), we can focus on the large groups.\n\n\np +\n  gghighlight(n() >= 100, use_direct_label = FALSE)\n\n\n\n\nOr small groups.\n\n\np +\n  gghighlight(n() < 10, use_direct_label = FALSE)\n\n\n\n\nYou can also use n() as a non-logical predicate, whose values are used for sorting data and the top max_highlight of rows/groups are highlighted.\n\n\n# Same result as above\np +\n  gghighlight(-n(), max_highlight = 2, use_direct_label = FALSE)\n\n\n\nTo unhighlight or not to unhighlight…\nBy default, unhighlighted data are grayed out. unhighlighted_params is the option to override this. Now, you can even choose not to unhighlight at all by specifying explicit NULL to colour or fill!\n\n\np +\n  gghighlight(n() < 10, use_direct_label = FALSE,\n              unhighlighted_params = list(colour = NULL))\n\n\n\n\nHmm…, but this is the very same plot as the original one. How can this be useful? Well, remember we still can tweak other parameters like alpha.\n\n\np +\n  gghighlight(n() < 10, use_direct_label = FALSE,\n              unhighlighted_params = list(colour = NULL, alpha = 0.2))\n\n\n\n\nThis plot doesn’t look very nice in that the colors are a bit difficult to distinguish. This is mainly because I didn’t come up with some nice data, but it’s generally a tough job to tweak colors by alpha properly, so I don’t recommend this much. But, hope you can find some good use case for this!\n\n\n\n",
    "preview": "post/2021-06-07-gghighlight-032/gghighlight-032_files/figure-html5/unhighlight2-1.png",
    "last_modified": "2021-06-07T09:47:37+09:00",
    "input_file": "gghighlight-032.knit.md"
  },
  {
    "path": "post/2021-06-06-unofficial-introduction-to-extendr-1-your-first-r-package-with-rust/",
    "title": "Unofficial Introduction To extendr (1): Your First R Package With Rust",
    "description": "Integrate R and Rust with extendr.",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2021-06-06",
    "categories": [
      "Rust",
      "extendr"
    ],
    "contents": "\n\nContents\nRust crates and R packages under extendr\nSetup\nCreate a template package\nPackage structure\nCompile and use the package\nRust code vs generated R code\nImplement a new Rust function\nWhat’s not covered in this post\n\nextendr is a project that provides an interface between R and Rust. While I’m also a member of this project, my contributions were small and I’m still a newbie to Rust, so let me add “Unofficial” to the title at the moment :P\nFor the full introduction, including the motivation to use Rust, please watch this great presentation by Claus Wilke:\n\n\nThe talk covers almost everything (history of the project, getting started with Rust, and how to compile a Rust function into an R function), so, instead of providing an overview, this post will focus on the one missing topic, how to write an R package using (r)extendr.\nRust crates and R packages under extendr\nThat said, to avoid confusion, probably I need to write a minimal introduction about the crates and packages we’ll look into… Let’s take a look briefly.\nlibR-sys (Rust crate)\nlibR-sys is low-level bindings to R’s C API, and powers extendr. This is not what the ordinary users use directly, so we can forget this name for now.\nextendr (Rust crate)\nextendr is a user-friendly Rust interface to R. To be precise, “extendr” itself is not a crate’s name; it’s extendr-api that we’ll actually use. There are some more crates that might be needed in some use cases, but let’s forget them for now.\nrextendr (R package)\nrextendr is an R package. This provides two types of functions:\nFunctions for compiling and running Rust code on the fly (e.g. rust_function())\nFunctions for developing R package using extendr\nWhat we’ll use in this post is type 2.\nSetup\nRust\nFirst of all, you need Rust.\nIf you are using macOS or Linux, you can follow the official guide. That’s all.\nIf you are using Windows, extendr requires you to install the latest Rtools, and use the following toolchains:\nrustup default stable-msvc\nrustup target add x86_64-pc-windows-gnu  # 64-bit\nrustup target add i686-pc-windows-gnu    # 32-bit\nFor the details, please refer to the installation instructions on libR-sys’s repo.\nrextendr\nrextendr is not on CRAN at the time of writing this blog post, so please install it from GitHub.\n\n\nremotes::install_github(\"extendr/rextendr\")\n\n\n\nCreate a template package\nCreating an R package with extendr is very easy with usethis and rextendr.\nFirst, create an R package by using usethis::create_package() as usual.\n\n\nusethis::create_package(\"path/to/my1stextendrpkg\")\n\n\n\nThen, create the scaffolding to use extendr. This can be done with rextendr::use_extendr().\n\n\nrextendr::use_extendr()\n\n\n\n✓ Creating src/rust/src.\n✓ Setting active project to 'path/to/my1stextendrpkg'\n✓ Writing 'src/entrypoint.c'\n✓ Writing 'src/Makevars'\n✓ Writing 'src/Makevars.win'\n✓ Writing 'src/.gitignore'\n✓ Writing src/rust/Cargo.toml.\n✓ Writing 'src/rust/src/lib.rs'\n✓ Writing 'R/extendr-wrappers.R'\n✓ Finished configuring extendr for package my1stextendrpkg.\n• Please update the system requirement in DESCRIPTION file.\n• Please run `rextendr::document()` for changes to take effect.\nDone! Now we are just one step away (as the message says, we need to run rextendr::document()) from calling Rust fucntions from R. But, before moving forward, let’s look at the files added.\nPackage structure\nThe below files are the ones rextendr::use_extendr() added.\n.\n├── R\n│   └── extendr-wrappers.R\n...\n└── src\n    ├── Makevars\n    ├── Makevars.win\n    ├── entrypoint.c\n    └── rust\n        ├── Cargo.toml\n        └── src\n            └── lib.rs\nR/extendr-wrappers.R: This file contains auto-generated R functions from Rust code. We don’t modify this by hand.\nsrc/Makevars, src/Makevars.win: This hooks cargo build at the installation of the R package. In most of the cases, we don’t edit these.\nsrc/entrypoint.c: This is needed to avoid the linker removing the static library. In 99.9% of the cases, we don’t edit this (except for changing the crate name).\nsrc/rust/: Rust code of a crate using extendr-api. This is where we mainly write code.\nSo, in short, what we should really look at is only these two files:\nsrc/rust/Cargo.toml\n[package]\nname = 'my1stextendrpkg'\nversion = '0.1.0'\nedition = '2018'\n\n[lib]\ncrate-type = [ 'staticlib' ]\n\n[dependencies]\nextendr-api = '*'\nThe create name is the same name as the R package’s name by default. You can change this, but it might be a bit tired to tweak other files accordingly, so I recommend leaving this.\nTo try the dev version of the extendr, you can modify the last line to\nextendr-api = { git = 'https://github.com/extendr/extendr' }\nsrc/rust/src/lib.rs\nuse extendr_api::prelude::*;\n\n/// Return string `\"Hello world!\"` to R.\n/// @export\n#[extendr]\nfn hello_world() -> &'static str {\n    \"Hello world!\"\n}\n\n// Macro to generate exports.\n// This ensures exported functions are registered with R.\n// See corresponding C code in `entrypoint.c`.\nextendr_module! {\n    mod my1stextendrpkg;\n    fn hello_world;\n}\nLet’s explain this part by part.\nThe first line use extendr_api::prelude::*; loads functions used frequently.\nNext, your eyes might notice the / are repeated 3 times, while the usual Rust comment requires only twice (i.e. //). These are treated as roxygen comments and copied to the auto-generated R code. This is analogous to Rcpp/cpp11’s //'.\n/// Return string `\"Hello world!\"` to R.\n/// @export\nThe next line is the core of extendr’s mechanism. If the function is marked with this macro, the corresponding R function will be generated automatically (I’ll explain the detail later). This is analogous to Rcpp’s [[Rcpp::export]] and cpp11’s [[cpp11::register]].\n#[extendr]\nThe last 3 lines are the macro for generating exports, as the comment explains. If we implement another function than hello_world, it needs to be listed here as well as marking it with #[extendr] macro.\nextendr_module! {\n    mod my1stextendrpkg;\n    fn hello_world;\n}\nCompile and use the package\nCompile\nCompiling Rust code into R functions is as easy as this one command:\n\n\nrextendr::document()\n\n\n\n✓ Saving changes in the open files.\nℹ Generating extendr wrapper functions for package: my1stextendrpkg.\n! No library found at src/my1stextendrpkg.so, recompilation is required.\nRe-compiling my1stextendrpkg\n─  installing *source* package ‘my1stextendrpkg’ ... (347ms)\n   ** using staged installation\n   ** libs\n   rm -Rf my1stextendrpkg.so ./rust/target/release/libmy1stextendrpkg.a entrypoint.o\n   gcc -std=gnu99 -I\"/usr/share/R/include\" -DNDEBUG      -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-tbZjLv/r-base-4.1.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c entrypoint.c -o entrypoint.o\n   cargo build --lib --release --manifest-path=./rust/Cargo.toml\n       Updating crates.io index\n      Compiling proc-macro2 v1.0.27\n      Compiling unicode-xid v0.2.2\n      Compiling libR-sys v0.2.1\n      Compiling syn v1.0.72\n      Compiling extendr-engine v0.2.0\n      Compiling lazy_static v1.4.0\n      Compiling quote v1.0.9\n      Compiling extendr-macros v0.2.0\n      Compiling extendr-api v0.2.0\n      Compiling my1stextendrpkg v0.1.0 (path/to/my1stextendrpkg/src/rust)\n       Finished release [optimized] target(s) in 19.05s\n   gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -Wl,-z,relro -o my1stextendrpkg.so entrypoint.o -L./rust/target/release -lmy1stextendrpkg -L/usr/lib/R/lib -lR\n   installing to /tmp/RtmpfMcL08/devtools_install_e2d6351b843c/00LOCK-my1stextendrpkg/00new/my1stextendrpkg/libs\n   ** checking absolute paths in shared objects and dynamic libraries\n─  DONE (my1stextendrpkg)\n✓ Writing 'R/extendr-wrappers.R'.\nℹ Updating my1stextendrpkg documentation\nℹ Loading my1stextendrpkg\nWriting NAMESPACE\nWriting NAMESPACE\nWriting hello_world.Rd\nYou might wonder why compilation is triggered while the function name is just document(). Well, this is because the compilation is actually needed to generate document from Rust code. This is consistent with devtools::document()’s behavior for C/C++ codes1.\nAnyway, by doing above, the following files are updated or generated:\n.\n...\n├── NAMESPACE                       ----------(4)\n├── R\n│   └── extendr-wrappers.R          ----------(3)\n├── man\n│   └── hello_world.Rd              ----------(4)\n└── src\n    ├── my1stextendrpkg.so          ----------(2)\n    └── rust\n        └── target\n            └── release\n                ├── libmy1stextendrpkg.a   ---(1)\n                ...\nsrc/rust/target/release/libmy1stextendrpkg.a (the extension depends on the OS): This is the static library built from Rust code. This will be then used for compiling shared library my1stextendrpkg.so.\nsrc/my1stextendrpkg.so (the extension depends on the OS): This is the shared object that is actually called from R.\nR/extendr-wrappers.R: The auto-generated R functions, including roxygen comments, goes to this file. The roxygen comments are accordingly converted into Rd files and NAMESPACE.\nman/, NAMESPACE: These are generated from roxygen comments.\nLoad and use\nAs all things are done by rexetndr::document() already, we can just load it (or install it if you want) and call the function.\n\n\ndevtools::load_all(\".\")\n\nhello_world()\n\n\n\n\n[1] \"Hello world!\"\n\nAchievement unlocked, you called a Rust function from R!\nRust code vs generated R code\nWe don’t open R/extendr-wrappers.R yet. While we never edit this file by hand, it might be good to know what R code is generated from a Rust code. Here it is:\n# Generated by extendr: Do not edit by hand\n#\n# This file was created with the following call:\n#   .Call(\"wrap__make_my1stextendrpkg_wrappers\", use_symbols = TRUE, package_name = \"my1stextendrpkg\")\n\n#' @docType package\n#' @usage NULL\n#' @useDynLib my1stextendrpkg, .registration = TRUE\nNULL\n\n#' Return string `\"Hello world!\"` to R.\n#' @export\nhello_world <- function() .Call(wrap__hello_world)\n.Call(\"wrap__make_my1stextendrpkg_wrappers\", use_symbols = ... is what was actually done inside rextendr::document().\nA section of @docType package is needed to generate useDynLib(my1stextendrpkg, .registration = TRUE) entry in NAMESPACE.\nThe last section is for hello_world(). We can see the roxygen comments are copied to here. As the Rust function hello_world() has no arguments so this R function also has no arguments. If the function is like this,\nfn add(x: i32, y: i32) -> i32 {\n    x + y\n}\nthen the generated function also has arguments like this:\nadd <- function(x, y) .Call(wrap__add, x, y)\nImplement a new Rust function\nNow that we roughly figured out how extendr works (hopefully!), let’s implment a new Rust function. The development flow would be:\nModify src/rust/src/lib.rs\nRun rextendr::document()\nRun devtools::load_all(\".\") and test the function\nAs an exercise, let’s add add(i32, i32) I showed above.\n1. Modify src/rust/src/lib.rs\nAdd the function with @export.\n/// @export\n#[extendr]\nfn add(x: i32, y: i32) -> i32 {\n    x + y\n}\nDon’t forget to add the function to extendr_module!.\nextendr_module! {\n    mod my1stextendrpkg;\n    fn hello_world;\n    fn add;\n}\n2. Run rextendr::document()\nJust run the command:\n\n\nrextendr::document()\n\n\n\n3. Run devtools::load_all(\".\") and test the function\nDitto.\n\n\ndevtools::load_all(\".\")\n\nadd(1L, 2L)\n\n\n\n\n[1] 3\n\nAchievement unlocked, you called a Rust function you implemented from R!\nWhat’s not covered in this post\nI hope this post illustrates how easy it is to get started with extendr to create an R package. But, if you play with the function, you might get wondered about the topics that this post doesn’t cover.\nFor example, while the signature is i32 (i.e. integer), the function also accepts numeric. What’s the rule behind this coercion? (Confession: I need to study to answer this question…)\n\n\nadd(1, 2)\n\n\n[1] 3\n\nAnother question might be how to handle vectors. This function accepts only length-one vectors. Otherwise, it errors. (Spoiler: This is very simple; we can use Vec<_>. But, let me leave this topic to the next post…)\n\n\nadd(1:2, 2:3)\n\n\nError in add(1:2, 2:3): Input must be of length 1. Vector of length >1 given.\n\nI’ll try explaining these in the next post. Stay tuned…\nUntil then, you can ask questions on extendr’s Discord, which you can find on https://github.com/extendr/extendr#contributing :)\nThe current mechanism under devtools::document() doesn’t have extensible mechanism for other languages than C/C++ (c.f. r-lib/pkgbuild#115), so we needed to have our own one.\n\n↩︎\n",
    "preview": {},
    "last_modified": "2021-06-07T13:05:52+09:00",
    "input_file": "unofficial-introduction-to-extendr-1-your-first-r-package-with-rust.knit.md"
  },
  {
    "path": "post/2021-06-05-tips-to-turn-r-markdown-into-slidev-presentation/",
    "title": "Tips To Turn R Markdown Into Slidev Presentation",
    "description": "Slidev is a tool to create slides from Markdown. This post is about some tips\nto use it in combination with R Markdown.",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2021-06-05",
    "categories": [
      "R Markdown",
      "Slidev"
    ],
    "contents": "\n\nContents\nGetting started\nChoose md_document\nPreserve YAML front-matter\nPer-slide YAML Front-matter\nSetting Base URL\nAdd blank lines between custom tags\nDeploy to GitHub Pages\nLimitations\n\nSlidev is a tool to create slides from Markdown. Recently, I used this with R Markdown and it was generally comfortable to use.\nSlides: https://tokyor92-slides-rust-and-r.vercel.app/That said, there were some points I needed to google around to find solutions, so let me share these in this post.\n(You might wonder what this presentation talks about R and Rust, but the contents are all in Japanese, sorry. I’m preparing another blog post for this, so stay tuned!)\nGetting started\nFirst of all, we need to create a project that has Slidev installed. This is done by:\nnpm init slidev\nThen, you’ll be asked several questions:\n❯ npm init slidev\nnpx: installed 22 in 3.269s\n\n  ●■▲\n  Slidev Creator  v0.19.6\n\n✔ Project name: … slidev-rmarkdown-test\n  Scaffolding project in slidev-rmarkdown-test ...\n  Done.\n\n✔ Install and start it now? … yes\n✔ Choose the agent › npm\n[ .................] / fetchMetadata: sill pacote version manifest for @nodelib/fs.scandir@2.1.5 fetched in 2883ms\nProject name will be the directory name of the new project, so choose a name that doesn’t exist yet.\nAfter finishing the installation, a web browser is launched and displays the template slides. These slides are generated from slides.md by a local Node.js server. slides.md is located in the top directory of the project created right now.\n❯ tree -L 1 slidev-rmarkdown-test\nslidev-rmarkdown-test\n|-- README.md\n|-- components\n|-- netlify.toml\n|-- node_modules\n|-- package-lock.json\n|-- package.json\n|-- slides.md\n`-- vercel.json\n\n2 directories, 6 files\n\nSo, what we should do next is obvious; let’s place slides.Rmd in the same directory so that we can render it to overwrite slides.md. The Node.js server detects the change on slides.md and regenerates slides from it on the fly.\nWe can stop the server with Ctrl+C on console. To launch again, execute this:\nnpm run dev\nChoose md_document\nFirst of all, the target we want to generate is a Markdown file, so let’s specify md_document as the output.\n---\n# R Markdown metadata\ntitle: R Markdown to Slidev\noutput:\n  md_document:\n    variant: \"markdown_github\"\n---\nPreserve YAML front-matter\nWhat’s a bit tricky here is that Slidev also uses YAML front-matter for defining metadata. So, we need to put both items for R Markdown and those for Slidev together, and preserve it after rendering. Let’s specify preserve_yaml: true.\n---\n...\n  md_document:\n    variant: \"markdown_github\"\n    preserve_yaml: true\n---\nThen, put settings for Slidev. There might be some name collision between R Markdown and Slidev, but I don’t find it yet, fortunately. The full YAML would be like this:\n---\n# R Markdown metadata\ntitle: R Markdown to Slidev\noutput:\n  md_document:\n    variant: \"markdown_github\"\n    preserve_yaml: true\n\n# Slidev metadata\ntheme: seriph\nbackground: ./images/top.gif\nclass: 'text-center'\nhighlighter: shiki\ninfo: |\n  ## Use Slidev with R Markdown\n  \n  Source code can be found on <https://github.com/yutannihilation/slidev-rmarkdown>.\n---\nPer-slide YAML Front-matter\nOne of the great things with Slidev is that it’s very customizable. Per-slide YAML Front-matter is a good example of this; for example, we can specify layout per slide like this (image is a specific parameter for image-right layout):\n---\nlayout: image-right\nimage: './images/image.png'\n---\nThis will generate a slide like this:\nslidesBut, the problem is, R Markdown (or probably underlying Pandoc?) seems to allow only one YAML front-matter. So, if we simply write\n---\nlayout: image-right\nimage: './images/image.png'\n---\nit will just disappear, alas… What can we do??\nWell, we can use Pandoc’s raw attribute to bypass the unnecessary conversion.\n```{=html}\n---\nlayout: image-right\nimage: './images/image.png'\n---\n```\nSetting Base URL\nThe base.url chunk option must be specified, otherwise the generated images will be broken. If the slides will be served on the root path (/), the setting should be like this:\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<div class=\"sourceCode\"><pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class='fu'>knitr<\/span><span class='fu'>::<\/span><span class='va'><a href='https://rdrr.io/pkg/knitr/man/opts_knit.html'>opts_knit<\/a><\/span><span class='op'>$<\/span><span class='fu'>set<\/span><span class='op'>(<\/span>base.url <span class='op'>=<\/span> <span class='st'>\"/\"<\/span><span class='op'>)<\/span>\n<\/code><\/pre><\/div>\n\n<\/div>\nFor another example, if the presentation is served under some path like /slides/presentation1, then the base.url should be like this:\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<div class=\"sourceCode\"><pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class='fu'>knitr<\/span><span class='fu'>::<\/span><span class='va'><a href='https://rdrr.io/pkg/knitr/man/opts_knit.html'>opts_knit<\/a><\/span><span class='op'>$<\/span><span class='fu'>set<\/span><span class='op'>(<\/span>base.url <span class='op'>=<\/span> <span class='st'>\"/slides/presentation1/\"<\/span><span class='op'>)<\/span>\n<\/code><\/pre><\/div>\n\n<\/div>\nAdd blank lines between custom tags\nSlidev provides some custome tags. For example, <v-click> is a tag to apply annimations (c.f. https://sli.dev/guide/animations.html). But, for unknown reason, this won’t work (I don’t find the reason yet, but I think something is happening in conversions by Pandoc):\n<v-click>\n* item1\n<\/v-click>\n<v-click>\n* item2\n<\/v-click>\nIt seems we need to insert blank lines between the tags.\n<v-click>\n\n* item1\n\n<\/v-click>\n\n<v-click>\n\n* item2\n\n<\/v-click>\nDeploy to GitHub Pages\nSlidev needs Node.js server to serve the slides, but it can also be exported as an standalone single-page application by the following command:\nnpm run build\nThe generated result goes to dist/, which can be deployed to GitHub Pages.\nSlidev also provides PDF export. For more details, please refer to the official document.\nLimitations\nWhile Slidev has many cool features, I doubt it can be an R package like revealjs or xaringan, as Slidev requires Node.js to build or run, which is not very portable. So, I’m not sure how useful this post is to R users, but hope you enjoy!\n\n\n\n",
    "preview": "post/2021-06-05-tips-to-turn-r-markdown-into-slidev-presentation/./images/slide.jpeg",
    "last_modified": "2021-06-07T00:10:26+09:00",
    "input_file": "tips-to-turn-r-markdown-into-slidev-presentation.knit.md"
  },
  {
    "path": "post/some-more-notes-about-using-rust-code-in-r-packages/",
    "title": "Some more notes about using Rust code in R packages",
    "description": "",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2020-09-15",
    "categories": [
      "Rust"
    ],
    "contents": "\n\nContents\nPassing a string from R to Rust\nPassing a vector from Rust to R, or vice versa\nUpdate: free the Rust-allocated memory\nPrecompiled binary for Windows\nWhy Rust?\n\nWhen I first tried to use Rust code within R package five years ago, it was like crawling in the dark and I wasted several days just to find I didn’t understand anything. But, now we have Using Rust code in R packages, a great presentation by Jeroen Ooms. It taught me almost everything! But still, I needed to learn myself some more things for my purpose. Let me leave some notes about those.\nPassing a string from R to Rust\nhellorust covers how to pass a string from Rust to R, but not the vice versa. I learned this from the code on clauswilke/sinab.\nFor example, let’s consider an improved version of hellorust::hello() that takes an argument name to say hello to.\nR code\nLet’s name it hello2.\nhello2 <- function(name) {\n  .Call(hello_wrapper2, name)\n}\nC code\nhello_wrapper2 would be like the code below. STRING_ELT(x, i) takes i-th element of a character vector x, and Rf_translateCharUTF8() converts it to a pointer to the string encoded in UTF-8.\nSEXP hello_wrapper2(SEXP name){\n  char* res = string_from_rust2(Rf_translateCharUTF8(STRING_ELT(name, 0)));\n  return Rf_ScalarString(Rf_mkCharCE(res, CE_UTF8));\n}\napi.h\nThe string is passed as const char *.\nchar * string_from_rust2(const char *);\nRust code\nThe function takes the string as *const c_char. If we process the string in Rust code, we need to create a String. This is done by std::ffi::CStr::from_ptr(). CStr is a representation of a borrowed C string, and can be converted to String by to_string() or to_string_lossy(). Since this is an unsafe operation, it needs to be wrapped with unsafe.\nuse std;\nuse std::ffi::{CStr, CString};\nuse std::os::raw::c_char;\n\n// Utility function to convert c_char to string\nfn c_char_to_string(c: *const c_char) -> String {\n    unsafe { CStr::from_ptr(c).to_string_lossy().into_owned() }\n}\n\n#[no_mangle]\npub extern fn string_from_rust2(c_name: *const c_char) -> *const c_char {\n    let name = c_char_to_string(c_name);\n\n    let s = CString::new(format!(\"Hello {} !\", name)).unwrap();\n    let p = s.as_ptr();\n    std::mem::forget(s);\n    p\n}\nResult\nYou can view the diff here:\nhttps://github.com/r-rust/hellorust/commit/a42346c728a408fb1b2e6e7522082e19ec5b8a04\nPassing a vector from Rust to R, or vice versa\n(Update: this code is incomplete, please read the next section as well)\nIt took me some time to figure out how to handle arrays. I’m still not confident if I understand this correctly, but let me try to explain…\nWe cannot simply pass a variable length of vector to FFI because the length is not known. So, what we need to do is obvious; pass the data with the length at the same time. To do this, we need to define the same struct both in C and in Rust.\nSuppose we want to implement a function that takes one double vector and reverse it.\nIn api.h, let’s define a struct named Slice:\ntypedef struct\n{\n  double *data;  // since we want to process `REALSXP` here, the data type is `double`\n  uint32_t len;\n} Slice;\nand in Rust code define the same one. #[repr(C)] means “do what C does.” This is needed to match the alignment of the field with C.\nuse std::os::raw::{c_double, c_uint};\n\n#[repr(C)]\npub struct Slice {\n    data: *mut c_double,\n    len: c_uint,\n}\nR code\nThe R code is pretty simple.\nrev <- function(x) {\n  x <- as.double(x)\n  .Call(rev_wrapper, x)\n}\nC code\nWe need to allocate a REALSXP vector and copy the result into it.\nSEXP rev_wrapper(SEXP x){\n  Slice s = {REAL(x), Rf_length(x)};\n  Slice s_rev = rev_slice(s);\n\n  SEXP out = PROTECT(Rf_allocVector(REALSXP, s_rev.len));\n  for (int i = 0; i < s_rev.len; i++) {\n    SET_REAL_ELT(out, i, s_rev.data[i]);\n  }\n  UNPROTECT(1);\n\n  return out;\n}\nRust code\nTo convert the Slice into Rust’s slice, we can use std::slice::from_raw_parts_mut. This is unsafe operation, so it needs to be wrapped with unsafe.\nslice and vector can be converted into an unsafe pointer by as_mut_ptr().\n#[no_mangle]\npub extern fn rev_slice(s: Slice) -> Slice {\n    // convert from Slice to Rust slice\n    let s = unsafe { std::slice::from_raw_parts_mut(s.data, s.len as _) };\n\n    let mut v = s.to_vec();\n    v.reverse();\n    let len = v.len();\n\n    let v_ptr = v.as_mut_ptr();\n    std::mem::forget(v);\n\n    Slice {\n        data: v_ptr,\n        len: len as _,\n    }\n}\nResult\nYou can view the diff here:\nhttps://github.com/r-rust/hellorust/commit/e278d1541301ae18446bf1149a15d7aed868bd51\nUpdate: free the Rust-allocated memory\nThe code above works, but I noticed the memory is never freed. Yes, that’s because I forgot to free it. This was my nice lesson to learn that Rust is not always automatically saving me from doing silly things :P\nOf course we can free it, but it’s a bit tricky. Since Slice is allocated by Rust, it needs to be freed by Rust (c.f. How to return byte array from Rust function to FFI C? - help - The Rust Programming Language Forum). (IIUC, if the length is known in advance, it might be good idea to allocate on C’s side and pass it to the Rust, as the answer on the forum above suggests. rev() is the case, but let me explain the different one for now…)\nRust code\nLet’s define a Rust function to free the memory. Box::from_raw() constructs a Box, a pointer for heap allocation, from the raw pointer. After that, the raw pointer is owned by the box, which means it’s now Rust’s role to destruct it and free the memory.\n#[no_mangle]\npub extern \"C\" fn free_slice(s: Slice) {\n    // convert to Rust slice\n    let s = unsafe { std::slice::from_raw_parts_mut(s.data, s.len as _) };\n    let s = s.as_mut_ptr();\n    unsafe {\n        Box::from_raw(s);\n    }\n}\nI still don’t understand how to use Box properly, but it seems Sized structs can be handled simpler using Box in the argument: https://doc.rust-lang.org/std/boxed/index.html#memory-layout\nC code\nCall the function above from C to free the memory as soon as it’s no longer in use.\n// Need to include to use memcpy()\n#include <string.h>\n\n// ...snip...\n\nSEXP rev_wrapper(SEXP x){\n  Slice s = {REAL(x), Rf_length(x)};\n  Slice s_rev = rev_slice(s);\n\n  SEXP out = PROTECT(Rf_allocVector(REALSXP, s_rev.len));\n  memcpy(REAL(out), s_rev.data, s.len * sizeof(double));\n  free_slice(s_rev); // free!!!\n  UNPROTECT(1);\n\n  return out;\n}\nResult\nThe full diff is here:\nhttps://github.com/r-rust/hellorust/commit/97b3628b4a66eae9e25898a79ebf20fa59741063\nCan I do zero-copy?\nCopying memory to memory is not very cool, but it just works. I don’t know any nicer way yet. Apache Arrow seems a overkill for this simple usage, but will I need it in future…? Or flatbuffer? This seems a battle for another day, so I’ll stop here for now.\nPrecompiled binary for Windows\nAs you might already notice, hellorust’s installation instruction for Windows is a bit long. But, do I really need to require the users to install cargo, just to compile my useless package? Now that we have GitHub Actions CI, maybe preparing a precompiled binary is a choice.\nHere’s the YAML I’m using to compile on windows runners and attach the binary on the releases (This creates a two separate releases for x86_64 and i686, which might be improved…).\non:\n  push:\n    tags:\n      - 'windows*'\n\nname: Build Windows\n\njobs:\n  build:\n    strategy:\n      matrix:\n        target:\n          - x86_64\n          - i686\n\n    name: build-${{ matrix.target }}-pc-windows-gnu\n\n    runs-on: windows-latest\n\n    steps:\n      - name: Checkout sources\n        uses: actions/checkout@v2\n\n      - name: Install stable toolchain\n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: stable\n          target: ${{ matrix.target }}-pc-windows-gnu\n          profile: minimal\n          default: true\n\n      - name: Run cargo build\n        uses: actions-rs/cargo@v1\n        with:\n          command: build\n          args: --release --target=${{ matrix.target }}-pc-windows-gnu --manifest-path=src/string2path/Cargo.toml\n\n      - name: List files\n        run: ls ./src/string2path/target/${{ matrix.target }}-pc-windows-gnu/release/\n        shell: bash\n\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}-${{ matrix.target }}\n          release_name: Release ${{ github.ref }}-${{ matrix.target }}\n          draft: false\n          prerelease: true\n      - name: Upload Release Asset\n        id: upload-release-asset\n        uses: actions/upload-release-asset@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.create_release.outputs.upload_url }}\n          asset_path: ./src/string2path/target/${{ matrix.target }}-pc-windows-gnu/release/libstring2path.a\n          asset_name: libstring2path.a\n          asset_content_type: application/octet-stream\nIf there’s a precompiled binary, we can skip the compilation by tweaking Makevars.win like this:\nCRATE = string2path\n\n# Change this when created a new tag\nBASE_TAG = windows7\n\nTARGET = $(subst 64,x86_64,$(subst 32,i686,$(WIN)))\nLIBDIR = windows/$(TARGET)\nSTATLIB = $(LIBDIR)/lib$(CRATE).a\nPKG_LIBS = -L$(LIBDIR) -l$(CRATE) -lws2_32 -ladvapi32 -luserenv\n\nall: clean\n\n$(SHLIB): $(STATLIB)\n\n$(STATLIB):\n    mkdir -p $(LIBDIR)\n    # Not sure, but $@ doesn't seem to work here...\n    curl -L -o $(STATLIB) https://github.com/yutannihilation/$(CRATE)/releases/download/$(BASE_TAG)-$(TARGET)/lib$(CRATE).a\n\nclean:\n    rm -Rf $(SHLIB) $(STATLIB) $(OBJECTS)\nBy the way, at the time when hellorust was created, the extension of staticlib was .lib on Windows (MinGW), but recently (as of v1.44) this is changed to .a. Be careful.\nWhy Rust?\nLastly, let me answer to what some of you might wonder. I know you want me to say something like “memory safe” or “fast,” but…, it was just I was more familiar with Rust than C/C++.\nI just happened to learn Rust. I was searching for some alternative of Processing, a great creative coding framework, and I found nannou. At first, I didn’t expect I needed to learn Rust seriously, as the framework wraps the things very nicely. But, since nannou is still maturing, I found I needed to dive a bit deeper into the world of Rust to make things work on my environment. I’m now learning wgpu, a Rust implementation of WebGPU. If you are interested in, here’s some resources:\nLearn WGPU\nA Taste of WebGPU in Firefox - Mozilla Hacks - the Web developer blog\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-14T21:17:09+09:00",
    "input_file": "2020-09-15-some-more-notes-about-using-rust-code-in-r-packages.knit.md"
  },
  {
    "path": "post/gghighlight-0-2-0/",
    "title": "gghighlight 0.2.0",
    "description": "gghighlight 0.2.0 is released!",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2020-02-17",
    "categories": [
      "gghighlight",
      "ggplot2",
      "package"
    ],
    "contents": "\ngghighlight 0.2.0 is on CRAN a while ago. This post briefly introduces the three new features. For basic usages, please refer to “Introduction to gghighlight”.\nkeep_scales\nTo put it simply, gghighlight doesn’t drop any data points but drops their colours. This means, while non-colour scales (e.g. x, y and size) are kept as they are, colour scales get shrinked. This might be inconvenient when we want to compare the original version and the highlighted version, or the multiple highlighted versions.\n\n\nlibrary(gghighlight)\nlibrary(patchwork)\n\nset.seed(3)\n\nd <- data.frame(\n  value = 1:9,\n  category = rep(c(\"a\",\"b\",\"c\"), 3),\n  cont_var = runif(9),\n  stringsAsFactors = FALSE\n)\n\np <- ggplot(d, aes(x = category, y = value, color = cont_var)) +\n  geom_point(size = 10) +\n  scale_colour_viridis_c()\n\np1 <- p + ggtitle(\"original\")\np2 <- p + \n  gghighlight(dplyr::between(cont_var, 0.3, 0.7),\n              use_direct_label = FALSE) +\n  ggtitle(\"highlighted\")\n\np1 * p2\n\n\n\n\nYou can see the colour of the points are different between the left plot and the right plot because the scale of the colours are different. In such a case, you can specify keep_scale = TRUE to keep the original scale (under the hood, gghighlight simply copies the original data to geom_blank()).\n\n\np3 <- p +\n  gghighlight(dplyr::between(cont_var, 0.3, 0.7),\n              keep_scales = TRUE,\n              use_direct_label = FALSE) +\n  ggtitle(\"highlighted (keep_scale = TRUE)\")\n\np1 * p3\n\n\n\n\ncalculate_per_facet\nWhen used with facet_*(), gghighlight() puts unhighlighted data on all facets and calculate the predicates on the whole data.\n\n\nSys.setlocale(locale = \"C\")\n\n\n[1] \"LC_CTYPE=C;LC_NUMERIC=C;LC_TIME=C;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=ja_JP.UTF-8;LC_PAPER=ja_JP.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=ja_JP.UTF-8;LC_IDENTIFICATION=C\"\n\nset.seed(16)\n\nd <- tibble::tibble(\n  day = rep(as.Date(\"2020-01-01\") + 0:89, times = 4),\n  month = lubridate::ceiling_date(day, \"month\"),\n  value = c(\n    cumsum(runif(90, -1.0, 1.0)),\n    cumsum(runif(90, -1.1, 1.1)),\n    cumsum(runif(90, -1.1, 1.0)),\n    cumsum(runif(90, -1.0, 1.1))\n  ),\n  id = rep(c(\"a\", \"b\", \"c\", \"d\"), each = 90)\n)\n\np <- ggplot(d) +\n  geom_line(aes(day, value, colour = id)) +\n  facet_wrap(~ month, scales = \"free_x\")\n\np + \n  gghighlight(mean(value) > 0, keep_scales = TRUE)\n\n\n\n\nBut, it sometimes feels better to highlight facet by facet. For such a need, gghighlight() now has a new argument calculate_per_facet.\n\n\np + \n  gghighlight(mean(value) > 0,\n              calculate_per_facet = TRUE,\n              keep_scales = TRUE)\n\n\n\n\nNote that, as a general rule, only the layers before adding gghighlight() are modified. So, if you add facet_*() after adding gghighlight(), this option doesn’t work (though this behaviour might also be useful in some cases).\n\n\nggplot(d) +\n  geom_line(aes(day, value, colour = id)) +\n  gghighlight(mean(value) > 0,\n              calculate_per_facet = TRUE,\n              keep_scales = TRUE) +\n  facet_wrap(~ month, scales = \"free_x\")\n\n\n\n\nunhighlighted_params\ngghighlight() now allows users to override the parameters of unhighlighted data via unhighlighted_params. This idea was suggested by [@ClausWilke](https://twitter.com/ClausWilke/status/1014529225402003456).\n\n\nI think you could support a broader set of use cases if you allowed a list of aesthetics default values, like bleach_aes = list(colour = &quot;grey40&quot;, fill =&quot;grey80&quot;, size = 0.2).\n\n— Claus Wilke (@ClausWilke) July 4, 2018\n\nTo illustrate the original motivation, let’s use an example on the ggridges’ vignette. gghighlight can highlight almost any Geoms, but it doesn’t mean it can “unhighlight” arbitrary colour aesthetics automatically. In some cases, you need to unhighlight them manually. For example, geom_density_ridges() has point_colour.\n\n\nlibrary(ggplot2)\nlibrary(gghighlight)\nlibrary(ggridges)\n\np <- ggplot(Aus_athletes, aes(x = height, y = sport, color = sex, point_color = sex, fill = sex)) +\n  geom_density_ridges(\n    jittered_points = TRUE, scale = .95, rel_min_height = .01,\n    point_shape = \"|\", point_size = 3, size = 0.25,\n    position = position_points_jitter(height = 0)\n  ) +\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0), name = \"height [cm]\") +\n  scale_fill_manual(values = c(\"#D55E0050\", \"#0072B250\"), labels = c(\"female\", \"male\")) +\n  scale_color_manual(values = c(\"#D55E00\", \"#0072B2\"), guide = \"none\") +\n  scale_discrete_manual(\"point_color\", values = c(\"#D55E00\", \"#0072B2\"), guide = \"none\") +\n  coord_cartesian(clip = \"off\") +\n  guides(fill = guide_legend(\n    override.aes = list(\n      fill = c(\"#D55E00A0\", \"#0072B2A0\"),\n      color = NA, point_color = NA)\n    )\n  ) +\n  ggtitle(\"Height in Australian athletes\") +\n  theme_ridges(center = TRUE)\n\np + \n  gghighlight(sd(height) < 5.5)\n\n\n\n\nYou should notice that these vertical lines still have their colours. To grey them out, we can specify point_colour = \"grey80\" on unhighlighted_params (Be careful, point_color doesn’t work…).\n\n\np + \n  gghighlight(sd(height) < 5.5, \n              unhighlighted_params = list(point_colour = \"grey80\"))\n\n\n\n\nunhighlighted_params is also useful when you want more significant difference between the highlighted data and unhighligted ones. In the following example, size and colour are set differently.\n\n\nset.seed(2)\nd <- purrr::map_dfr(\n  letters,\n  ~ data.frame(\n      idx = 1:400,\n      value = cumsum(runif(400, -1, 1)),\n      type = .,\n      flag = sample(c(TRUE, FALSE), size = 400, replace = TRUE),\n      stringsAsFactors = FALSE\n    )\n)\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type), size = 5) +\n  gghighlight(max(value) > 19,\n              unhighlighted_params = list(size = 1, colour = alpha(\"pink\", 0.4)))\n\n\n\n\n\n\n\n",
    "preview": "post/gghighlight-0-2-0/2020-02-17-gghighlight-0-2-0_files/figure-html5/keep_scale2-1.png",
    "last_modified": "2021-06-06T10:22:20+09:00",
    "input_file": {}
  },
  {
    "path": "post/enhancing-gather-and-spread-by-using-bundled-data-frames/",
    "title": "Enhancing gather() and spread() by Using \"Bundled\" data.frames",
    "description": "",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2019-02-03",
    "categories": [
      "tidyr",
      "tidy data"
    ],
    "contents": "\n\ntable {\n  width: 50%;\n  font-size: 80%;\n}\nLast month, I tried to explain gather() and spread() by gt package (https://yutani.rbind.io/post/gather-and-spread-explained-by-gt/). But, after I implemented experimental multi-gather() and multi-spread(), I realized that I need a bit different way of explanation… So, please forget the post, and read this with fresh eyes!\nWait, what is multi-gather() and multi-spread()??\nIn short, the current gather() and spread() have a limitation; they can gather into or spread from only one column at once. So, if we want to handle multiple columns, we need to coerce them to one column before actually gathering or spreading.\nThis is especially problematic when the columns have different types. For example, date column is unexpectedly converted to integers with the following code:\n\n\nlibrary(tibble)\nlibrary(tidyr)\n\n# a bit different version of https://github.com/tidyverse/tidyr/issues/149#issue-124411755\nd <- tribble(\n  ~place, ~censor,                  ~date, ~status,\n    \"g1\",    \"c1\",  as.Date(\"2019-02-01\"),   \"ok\",\n    \"g1\",    \"c2\",  as.Date(\"2019-02-01\"),  \"bad\",\n    \"g1\",    \"c3\",  as.Date(\"2019-02-01\"),   \"ok\",\n    \"g2\",    \"c1\",  as.Date(\"2019-02-01\"),  \"bad\",\n    \"g2\",    \"c2\",  as.Date(\"2019-02-02\"),   \"ok\"\n)\n\nd %>%\n  gather(key = element, value = value, date, status) %>%\n  unite(thing, place, element, remove = TRUE) %>%\n  spread(thing, value, convert = TRUE)\n\n\n# A tibble: 3 x 5\n  censor g1_date g1_status g2_date g2_status\n  <chr>    <int> <chr>       <int> <chr>    \n1 c1       17928 ok          17928 bad      \n2 c2       17928 bad         17929 ok       \n3 c3       17928 ok             NA <NA>     \n\nHere, we need better spread() and gather(), which can handle multiple columns. For more discussions, you can read the following issues:\nhttps://github.com/tidyverse/tidyr/issues/149\nhttps://github.com/tidyverse/tidyr/issues/150\nIn this post, I’m trying to explain an approach to solve this by using “bundled” data.frames, which is originally proposed by Kirill Müller.\n“Bundled” data.frames\nFor convenience, I use a new term “bundle” for separating some of the columns of a data.frame to another data.frame, and assigning the new data.frame to a column, and “unbundle” for the opposite operation.\nFor example, “bundling X, Y, and Z” means converting this\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#fabxpezwpt .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fabxpezwpt .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fabxpezwpt .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fabxpezwpt .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fabxpezwpt .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fabxpezwpt .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fabxpezwpt .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fabxpezwpt .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fabxpezwpt .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fabxpezwpt .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#fabxpezwpt .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#fabxpezwpt .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fabxpezwpt .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#fabxpezwpt .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fabxpezwpt .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fabxpezwpt .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fabxpezwpt .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fabxpezwpt .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fabxpezwpt .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fabxpezwpt .gt_left {\n  text-align: left;\n}\n\n#fabxpezwpt .gt_center {\n  text-align: center;\n}\n\n#fabxpezwpt .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fabxpezwpt .gt_font_normal {\n  font-weight: normal;\n}\n\n#fabxpezwpt .gt_font_bold {\n  font-weight: bold;\n}\n\n#fabxpezwpt .gt_font_italic {\n  font-style: italic;\n}\n\n#fabxpezwpt .gt_super {\n  font-size: 65%;\n}\n\n#fabxpezwpt .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nid\n      X\n      Y\n      Z\n    1\n0.1\na\nTRUE2\n0.2\nb\nFALSE3\n0.3\nc\nTRUE\n\nto something like this:\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#zcopkdaisg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#zcopkdaisg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#zcopkdaisg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#zcopkdaisg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#zcopkdaisg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#zcopkdaisg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#zcopkdaisg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#zcopkdaisg .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#zcopkdaisg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#zcopkdaisg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#zcopkdaisg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#zcopkdaisg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#zcopkdaisg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#zcopkdaisg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#zcopkdaisg .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#zcopkdaisg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#zcopkdaisg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#zcopkdaisg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#zcopkdaisg .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#zcopkdaisg .gt_left {\n  text-align: left;\n}\n\n#zcopkdaisg .gt_center {\n  text-align: center;\n}\n\n#zcopkdaisg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#zcopkdaisg .gt_font_normal {\n  font-weight: normal;\n}\n\n#zcopkdaisg .gt_font_bold {\n  font-weight: bold;\n}\n\n#zcopkdaisg .gt_font_italic {\n  font-style: italic;\n}\n\n#zcopkdaisg .gt_super {\n  font-size: 65%;\n}\n\n#zcopkdaisg .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nid\n      \n        foo\n      \n    X\n      Y\n      Z\n    1\n0.1\na\nTRUE2\n0.2\nb\nFALSE3\n0.3\nc\nTRUE\n\nYou might wonder if this is really possible without dangerous hacks. But, with tibble package (2D columns are supported now), this is as easy as:\n\n\ntibble(\n  id = 1:3,\n  foo = tibble(\n    X = 1:3 * 0.1,\n    Y = letters[1:3],\n    Z = c(TRUE, FALSE, TRUE)\n  )\n)\n\n\n# A tibble: 3 x 2\n     id foo$X $Y    $Z   \n  <int> <dbl> <chr> <lgl>\n1     1   0.1 a     TRUE \n2     2   0.2 b     FALSE\n3     3   0.3 c     TRUE \n\nFor more information about data.frame columns, please see Advanced R.\nAn experimental package for this\nI created a package for bundling, tiedr. Since this is just an experiment, I don’t seriously introduce this. But, for convenience, let me use this package in this post because, otherwise, the code would be a bit long and hard to read…\nhttps://github.com/yutannihilation/tiedr\nI need four functions from this package, bundle(), unbundle(), gather_bundles(), and spread_bundles(). gather_bundles() and spread_bundles() are some kind of the variants of gather() and spread(), so probably you can guess the usages. Here, I just explain about the first two functions briefly.\nbundle()\nbundle() bundles columns. It takes data, and the specifications of bundles in the form of new_col1 = c(col1, col2, ...), new_col2 = c(col3, col4, ...), ....\n\n\nlibrary(tiedr)\n\nd <- tibble(id = 1:3, X = 1:3 * 0.1, Y = letters[1:3], Z = c(TRUE, FALSE, TRUE))\n\nbundle(d, foo = X:Z)\n\n\n# A tibble: 3 x 2\n     id foo$X $Y    $Z   \n  <int> <dbl> <chr> <lgl>\n1     1   0.1 a     TRUE \n2     2   0.2 b     FALSE\n3     3   0.3 c     TRUE \n\nbundle() also can rename the sub-columns at the same time.\n\n\nbundle(d, foo = c(x = X, y = Y, z = Z))\n\n\n# A tibble: 3 x 2\n     id foo$x $y    $z   \n  <int> <dbl> <chr> <lgl>\n1     1   0.1 a     TRUE \n2     2   0.2 b     FALSE\n3     3   0.3 c     TRUE \n\nunbundle()\nunbundle() unbundles columns. This operation is almost the opposite of what bundle() does; one difference is that this adds the names of the bundle as prefixes in order to avoid name collisions. In case the prefix is not needed, we can use sep = NULL.\n\n\nd %>%\n  bundle(foo = X:Z) %>% \n  unbundle(foo)\n\n\n# A tibble: 3 x 4\n     id foo_X foo_Y foo_Z\n  <int> <dbl> <chr> <lgl>\n1     1   0.1 a     TRUE \n2     2   0.2 b     FALSE\n3     3   0.3 c     TRUE \n\nExpose hidden structures in colnames as bundles\nOne of the meaningful usage of bundled data.frame is to express the structure of a data. Suppose we have this data (from tidyverse/tidyr#150):\n\n\nd <- tribble(\n  ~Race,~Female_LoTR,~Male_LoTR,~Female_TT,~Male_TT,~Female_RoTK,~Male_RoTK,\n  \"Elf\",        1229,       971,       331,     513,         183,       510,\n  \"Hobbit\",       14,      3644,         0,    2463,           2,      2673,\n  \"Man\",           0,      1995,       401,    3589,         268,      2459\n)\n\n\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#hbglejqwuy .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#hbglejqwuy .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#hbglejqwuy .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#hbglejqwuy .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#hbglejqwuy .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#hbglejqwuy .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#hbglejqwuy .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#hbglejqwuy .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hbglejqwuy .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hbglejqwuy .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#hbglejqwuy .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#hbglejqwuy .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#hbglejqwuy .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#hbglejqwuy .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hbglejqwuy .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hbglejqwuy .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#hbglejqwuy .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#hbglejqwuy .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hbglejqwuy .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#hbglejqwuy .gt_left {\n  text-align: left;\n}\n\n#hbglejqwuy .gt_center {\n  text-align: center;\n}\n\n#hbglejqwuy .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#hbglejqwuy .gt_font_normal {\n  font-weight: normal;\n}\n\n#hbglejqwuy .gt_font_bold {\n  font-weight: bold;\n}\n\n#hbglejqwuy .gt_font_italic {\n  font-style: italic;\n}\n\n#hbglejqwuy .gt_super {\n  font-size: 65%;\n}\n\n#hbglejqwuy .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nRace\n      Female_LoTR\n      Male_LoTR\n      Female_TT\n      Male_TT\n      Female_RoTK\n      Male_RoTK\n    Elf\n1229\n971\n331\n513\n183\n510Hobbit\n14\n3644\n0\n2463\n2\n2673Man\n0\n1995\n401\n3589\n268\n2459\n\nIn this data, the prefixes Female_ and Male_ represent the column groups. Thus, as Kirill Müller suggests in the comment, these columns can be bundled (with the sub-columns renamed) to:\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#bqiouvsqwc .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#bqiouvsqwc .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#bqiouvsqwc .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#bqiouvsqwc .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#bqiouvsqwc .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#bqiouvsqwc .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#bqiouvsqwc .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#bqiouvsqwc .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#bqiouvsqwc .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#bqiouvsqwc .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#bqiouvsqwc .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#bqiouvsqwc .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#bqiouvsqwc .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#bqiouvsqwc .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#bqiouvsqwc .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#bqiouvsqwc .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#bqiouvsqwc .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#bqiouvsqwc .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#bqiouvsqwc .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#bqiouvsqwc .gt_left {\n  text-align: left;\n}\n\n#bqiouvsqwc .gt_center {\n  text-align: center;\n}\n\n#bqiouvsqwc .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#bqiouvsqwc .gt_font_normal {\n  font-weight: normal;\n}\n\n#bqiouvsqwc .gt_font_bold {\n  font-weight: bold;\n}\n\n#bqiouvsqwc .gt_font_italic {\n  font-style: italic;\n}\n\n#bqiouvsqwc .gt_super {\n  font-size: 65%;\n}\n\n#bqiouvsqwc .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nRace\n      \n        Female\n      \n      \n        Male\n      \n    LoTR\n      TT\n      RoTK\n      LoTR\n      TT\n      RoTK\n    Elf\n1229\n331\n183\n971\n513\n510Hobbit\n14\n0\n2\n3644\n2463\n2673Man\n0\n401\n268\n1995\n3589\n2459\n\nWith bundle() we can write this as:\n\n\nd_bundled <- d %>% \n  bundle(\n    Female = c(LoTR = Female_LoTR, TT = Female_TT, RoTK = Female_RoTK),\n    Male   = c(LoTR = Male_LoTR,   TT = Male_TT,   RoTK = Male_RoTK)\n  )\n\nd_bundled\n\n\n# A tibble: 3 x 3\n  Race   Female$LoTR   $TT $RoTK Male$LoTR   $TT $RoTK\n  <chr>        <dbl> <dbl> <dbl>     <dbl> <dbl> <dbl>\n1 Elf           1229   331   183       971   513   510\n2 Hobbit          14     0     2      3644  2463  2673\n3 Man              0   401   268      1995  3589  2459\n\ngather() the bundles\nRemember gather() strips colnames and convert it to a column. We can do this operation for bundled data.frames in the same manner. But, unlike gather() for flat data.frames, we don’t need to specify a colname for values, because the contents in bundles already have their colnames.\nLet’s gather Female and Male bundles into key column.\n\n\nd_gathered <- d_bundled %>%\n  gather_bundles(Female, Male, .key = \"key\")\n\nd_gathered\n\n\n# A tibble: 6 x 5\n  Race   key     LoTR    TT  RoTK\n  <chr>  <chr>  <dbl> <dbl> <dbl>\n1 Elf    Female  1229   331   183\n2 Hobbit Female    14     0     2\n3 Man    Female     0   401   268\n4 Elf    Male     971   513   510\n5 Hobbit Male    3644  2463  2673\n6 Man    Male    1995  3589  2459\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#atvoxfdosk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#atvoxfdosk .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#atvoxfdosk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#atvoxfdosk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#atvoxfdosk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#atvoxfdosk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#atvoxfdosk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#atvoxfdosk .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#atvoxfdosk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#atvoxfdosk .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#atvoxfdosk .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#atvoxfdosk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#atvoxfdosk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#atvoxfdosk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#atvoxfdosk .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#atvoxfdosk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#atvoxfdosk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#atvoxfdosk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#atvoxfdosk .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#atvoxfdosk .gt_left {\n  text-align: left;\n}\n\n#atvoxfdosk .gt_center {\n  text-align: center;\n}\n\n#atvoxfdosk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#atvoxfdosk .gt_font_normal {\n  font-weight: normal;\n}\n\n#atvoxfdosk .gt_font_bold {\n  font-weight: bold;\n}\n\n#atvoxfdosk .gt_font_italic {\n  font-style: italic;\n}\n\n#atvoxfdosk .gt_super {\n  font-size: 65%;\n}\n\n#atvoxfdosk .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nRace\n      key\n      LoTR\n      TT\n      RoTK\n    Elf\nFemale\n1229\n331\n183Hobbit\nFemale\n14\n0\n2Man\nFemale\n0\n401\n268Elf\nMale\n971\n513\n510Hobbit\nMale\n3644\n2463\n2673Man\nMale\n1995\n3589\n2459\n\nNow we have all parts for implementing multi-gather(). I did bundling by manual, but we can have a helper function to find the common prefixes and bundle them automatically. So, multi-gather() will be something like:\n\n\nd %>%\n  auto_bundle(-Race) %>% \n  gather_bundles()\n\n\n# A tibble: 6 x 5\n  Race   key     LoTR    TT  RoTK\n  <chr>  <chr>  <dbl> <dbl> <dbl>\n1 Elf    Female  1229   331   183\n2 Hobbit Female    14     0     2\n3 Man    Female     0   401   268\n4 Elf    Male     971   513   510\n5 Hobbit Male    3644  2463  2673\n6 Man    Male    1995  3589  2459\n\n\nspread() to the bundles\nAs we already saw it’s possible to gather() multiple bundles, now it’s obvious that we can spread() multiple columns into multiple bundles vice versa. So, let me skip the details here.\nWe can multi-spread():\n\n\nd_bundled_again <- d_gathered %>%\n  spread_bundles(key, LoTR:RoTK)\n\nd_bundled_again\n\n\n# A tibble: 3 x 3\n  Race   Female$LoTR   $TT $RoTK Male$LoTR   $TT $RoTK\n  <chr>        <dbl> <dbl> <dbl>     <dbl> <dbl> <dbl>\n1 Elf           1229   331   183       971   513   510\n2 Hobbit          14     0     2      3644  2463  2673\n3 Man              0   401   268      1995  3589  2459\n\nThen, unbundle() flattens the bundles to prefixes.\n\n\nd_bundled_again %>%\n  unbundle(-Race)\n\n\n# A tibble: 3 x 7\n  Race   Female_LoTR Female_TT Female_RoTK Male_LoTR Male_TT Male_RoTK\n  <chr>        <dbl>     <dbl>       <dbl>     <dbl>   <dbl>     <dbl>\n1 Elf           1229       331         183       971     513       510\n2 Hobbit          14         0           2      3644    2463      2673\n3 Man              0       401         268      1995    3589      2459\n\nIt’s done. By combining these two steps, multi-spread() will be something like this:\n\n\nd_gathered %>%\n  spread_bundles(key, LoTR:RoTK) %>% \n  unbundle(-Race)\n\n\n\nConsiderations\nAs I described above, multi-gather() doesn’t need the column name for value. On the other hand, usual gather() needs a new colname. Because, while it needs a name to become a column, an atomic column doesn’t have inner names.\nSimilarly, usual spread() can be considered as a special version of multi-spread(). Consider the case when we multi-spread()ing one column:\n\n\n# an example in ?tidyr::spread\ndf <- tibble(x = c(\"a\", \"b\"), y = c(3, 4), z = c(5, 6))\n\nspread_bundles(df, key = x, y, simplify = FALSE)\n\n\n# A tibble: 2 x 3\n      z   a$y   b$y\n  <dbl> <dbl> <dbl>\n1     5     3    NA\n2     6    NA     4\n\nSince y is the only one column in the data, we can simplify these 1-column data.frames to vectors:\n\n\nspread_bundles(df, key = x, y, simplify = TRUE)\n\n\n# A tibble: 2 x 3\n      z     a     b\n  <dbl> <dbl> <dbl>\n1     5     3    NA\n2     6    NA     4\n\nThis is usual spread().\nI’m yet to see if we can improve the current spread() and gather() to handle these differences transparently…\nFuture plans\nProbably, this post is too much about the implementational details. I need to think about the interfaces before proposing this on tidyr’s repo.\nAny suggestions or feedbacks are welcome!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:17:32+09:00",
    "input_file": {}
  },
  {
    "path": "post/a-survival-guide-to-install-rlang-from-github-on-windows/",
    "title": "A Survival Guide To Install rlang From GitHub On Windows",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2019-01-25",
    "categories": [
      "rlang",
      "Windows"
    ],
    "contents": "\nI don’t have any strong feelings about OSs. They are just tools. I had been a Mac user for 10+ years since I was 10, and now I’m using Windows for no reason. All OSs have their pros and cons. For example, I like Mac, but, in the late 90s, I was very disappointed at Mac because it didn’t have fonts to display Shift_JIS art nicely.\nAnyway, I’m using Windows and I need to survive. Here’s an error I often see when I try to install rlang package from GitHub by devtools::install_github():\ninstalling to C:/path/to/R/win-library/3.5/rlang/libs/x64\nError in file.copy(files, dest, overwrite = TRUE) : \n  (converted from warning) problem copying .\\rlang.dll to\nC:\\path\\to\\R\\win-library\\3.5\\rlang\\libs\\x64\\rlang.dll: Permission denied\nThis is because rlang.dll is used by the current R session (or other session?), so Windows won’t let me overwrite it. What should I do? Here’s some advice.\nRestart the R session\nThis is always necessary. Since rlang is very fundamental package, it might be loaded as a dependency of some attached or loaded package (if you are curious about the differences between load and attach, R Packages helps). You need a fresh session with no packages (except for base packages) loaded. On RStudio, Ctrl+Shift+F10, or “Restart R” in “Session” menu.\n\nFor usual packages, this is enough. But, rlang is not the case…\nUse remotes::install_github() instead of devtools\ndevtools::install_github() is just re-exported from remotes package. So, are the same one. But, if I use devtools::, devtools’s dependencies are loaded, and, at the moment, rlang is included here. So, the same error will occur.\nOn the other hand, remotes:: doesn’t need rlang directly or indirectly. So, run\nremotes::install_github(\"r-lib/rlang\")\n(You might also need remotes::install_github() for other dependency packages like glue.)\nNote that, pkg package seems aware of this kind of problems, so we’ll be free from this kind of problems when pkg is mature!\nExtra steps?\nUsually, restarting the session + using remotes::install_github() works. But, in the past, I needed some extra steps. I don’t know why, but it seemed RStudio loads rlang in background (c.f. https://github.com/r-lib/remotes/issues/131). So, for future references, I note some. Hope this will never be needed again…\nRemove rlang\nRemoving package might help, since removed package cannot be loaded.\nremove.packages(\"rlang\")\nUse git clone, R CMD build and R CMD INSTALL\nIf you really need to be away from RStudio, or even from any R sessions. In those cases, you can use git and R CMD build and R CMD INSTALL on console.\ngit clone https://github.com/r-lib/rlang\nR.exe CMD build --no-manual --no-build-vignettes rlang/\nR.exe CMD INSTALL [--some-options-i-dont-remember] rlang_*.tar.gz\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:16:46+09:00",
    "input_file": {}
  },
  {
    "path": "post/gather-and-spread-explained-by-gt/",
    "title": "gather() and spread() Explained By gt",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2019-01-24",
    "categories": [
      "tidyr",
      "tidy data",
      "gt"
    ],
    "contents": "\n\ntable {\n  width: 50%;\n  font-size: 80%;\n}\nThis is episode 0 of my long adventure to multi-spread and multi-gather (this is my homework I got at the tidyverse developer day…). This post might seem to introduce the different semantics from the current tidyr’s one, but it’s probably just because my idea is still vague. So, I really appreciate any feedbacks!\ntl;dr\nI now think gather() and spread() are about\ngrouping and\nenframe()ing and deframe()ing within each group\nDo you get what I mean? Let me explain step by step.\nWhat does gt teach us?\nA while ago, gt package, Richard Iannone’s work-in-progress great work, was made public.\ngt package is wonderful, especially in that it makes us rethink about the possible semantics of columns. I mean, not all columns are equal. No, I don’t say anything new; this is what you already know with spread() and gather().\nspread()ed data explained\nTake a look at this example data, a simpler version of the one in ?gather:\n\n\nlibrary(tibble)\nlibrary(gt)\n\nset.seed(1)\n# example in ?gather\nstocks <- tibble(\n  time = as.Date('2009-01-01') + 0:2,\n  X = rnorm(3, 0, 1),\n  Y = rnorm(3, 0, 2),\n  Z = rnorm(3, 0, 4)\n)\n\nstocks\n\n\n# A tibble: 3 x 4\n  time            X      Y     Z\n  <date>      <dbl>  <dbl> <dbl>\n1 2009-01-01 -0.626  3.19   1.95\n2 2009-01-02  0.184  0.659  2.95\n3 2009-01-03 -0.836 -1.64   2.30\n\nHere, X, Y, and Z are the prices of stock X, Y, and Z. Of course, we can gather() the columns as this is the very example for this, but, we also can bundle these columns using tab_spanner():\n\n\ngt(stocks) %>%\n  tab_spanner(\"price\", vars(X, Y, Z))\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#jgioueiyne .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#jgioueiyne .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#jgioueiyne .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#jgioueiyne .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#jgioueiyne .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#jgioueiyne .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#jgioueiyne .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#jgioueiyne .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jgioueiyne .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jgioueiyne .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#jgioueiyne .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#jgioueiyne .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#jgioueiyne .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#jgioueiyne .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jgioueiyne .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jgioueiyne .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#jgioueiyne .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#jgioueiyne .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jgioueiyne .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#jgioueiyne .gt_left {\n  text-align: left;\n}\n\n#jgioueiyne .gt_center {\n  text-align: center;\n}\n\n#jgioueiyne .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#jgioueiyne .gt_font_normal {\n  font-weight: normal;\n}\n\n#jgioueiyne .gt_font_bold {\n  font-weight: bold;\n}\n\n#jgioueiyne .gt_font_italic {\n  font-style: italic;\n}\n\n#jgioueiyne .gt_super {\n  font-size: 65%;\n}\n\n#jgioueiyne .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\ntime\n      \n        price\n      \n    X\n      Y\n      Z\n    2009-01-01\n-0.6264538\n3.1905616\n1.9497162009-01-02\n0.1836433\n0.6590155\n2.9532992009-01-03\n-0.8356286\n-1.6409368\n2.303125\n\nYet another option is to specify groupname_col. We roughly think each row is a group and time is the grouping variable here:\n\n\ngt(stocks, groupname_col = \"time\")\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ebjyloatcf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ebjyloatcf .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ebjyloatcf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ebjyloatcf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ebjyloatcf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ebjyloatcf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ebjyloatcf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ebjyloatcf .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ebjyloatcf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ebjyloatcf .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ebjyloatcf .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ebjyloatcf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ebjyloatcf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ebjyloatcf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ebjyloatcf .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ebjyloatcf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ebjyloatcf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ebjyloatcf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ebjyloatcf .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ebjyloatcf .gt_left {\n  text-align: left;\n}\n\n#ebjyloatcf .gt_center {\n  text-align: center;\n}\n\n#ebjyloatcf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ebjyloatcf .gt_font_normal {\n  font-weight: normal;\n}\n\n#ebjyloatcf .gt_font_bold {\n  font-weight: bold;\n}\n\n#ebjyloatcf .gt_font_italic {\n  font-style: italic;\n}\n\n#ebjyloatcf .gt_super {\n  font-size: 65%;\n}\n\n#ebjyloatcf .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nX\n      Y\n      Z\n    2009-01-01\n    -0.6264538\n3.1905616\n1.9497162009-01-02\n    0.1836433\n0.6590155\n2.9532992009-01-03\n    -0.8356286\n-1.6409368\n2.303125\n\ngather()ed data explained\nLet’s see the gathered version next. Here’s the data:\n\n\nstocksm <- stocks %>%\n  tidyr::gather(\"name\", \"value\", X:Z)\n\nstocksm\n\n\n# A tibble: 9 x 3\n  time       name   value\n  <date>     <chr>  <dbl>\n1 2009-01-01 X     -0.626\n2 2009-01-02 X      0.184\n3 2009-01-03 X     -0.836\n4 2009-01-01 Y      3.19 \n5 2009-01-02 Y      0.659\n6 2009-01-03 Y     -1.64 \n7 2009-01-01 Z      1.95 \n8 2009-01-02 Z      2.95 \n9 2009-01-03 Z      2.30 \n\nThis can be represented in a similar way. This time, a group doesn’t consist of a single row, but the rows with the same grouping values. Accordingly, the grouping is the same as above.\n\n\nstocksm %>%\n  gt(groupname_col = \"time\")\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#jjfottzlyw .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#jjfottzlyw .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#jjfottzlyw .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#jjfottzlyw .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#jjfottzlyw .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#jjfottzlyw .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#jjfottzlyw .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#jjfottzlyw .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jjfottzlyw .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jjfottzlyw .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#jjfottzlyw .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#jjfottzlyw .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#jjfottzlyw .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#jjfottzlyw .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jjfottzlyw .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jjfottzlyw .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#jjfottzlyw .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#jjfottzlyw .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jjfottzlyw .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#jjfottzlyw .gt_left {\n  text-align: left;\n}\n\n#jjfottzlyw .gt_center {\n  text-align: center;\n}\n\n#jjfottzlyw .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#jjfottzlyw .gt_font_normal {\n  font-weight: normal;\n}\n\n#jjfottzlyw .gt_font_bold {\n  font-weight: bold;\n}\n\n#jjfottzlyw .gt_font_italic {\n  font-style: italic;\n}\n\n#jjfottzlyw .gt_super {\n  font-size: 65%;\n}\n\n#jjfottzlyw .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\nname\n      value\n    2009-01-01\n    X\n-0.6264538Y\n3.1905616Z\n1.94971622009-01-02\n    X\n0.1836433Y\n0.6590155Z\n2.95329882009-01-03\n    X\n-0.8356286Y\n-1.6409368Z\n2.3031254\n\nYou can see the only difference is the rotation. So, theoretically, this can be implemented as grouping + rotating.\nDo it yourself by enframe() and deframe()\nBefore entering into the implementations, I explain two tibble’s functions, enframe() and deframe() briefly. They can convert a vector to/from a two-column data.frame.\n\n\nlibrary(tibble)\n\nx <- 1:3\nnames(x) <- c(\"foo\", \"bar\", \"baz\")\n\nenframe(x)\n\n\n# A tibble: 3 x 2\n  name  value\n  <chr> <int>\n1 foo       1\n2 bar       2\n3 baz       3\n\n\n\ndeframe(enframe(x))\n\n\nfoo bar baz \n  1   2   3 \n\ngather()\nFirst, nest the data by time.\n\n\nd <- dplyr::group_nest(stocks, time)\nd\n\n\n# A tibble: 3 x 2\n  time                     data\n  <date>     <list<tibble[,3]>>\n1 2009-01-01            [1 × 3]\n2 2009-01-02            [1 × 3]\n3 2009-01-03            [1 × 3]\n\nThen, coerce the columns of the 1-row data.frames to vectors. (In practice, we should check if the elements are all coercible.)\n\n\nd$data <- purrr::map(d$data, ~ vctrs::vec_c(!!! .))\nd\n\n\n# A tibble: 3 x 2\n  time       data     \n  <date>     <list>   \n1 2009-01-01 <dbl [3]>\n2 2009-01-02 <dbl [3]>\n3 2009-01-03 <dbl [3]>\n\nLastly, enframe() the vectors and unnest the whole data.\n\n\nd$data <- purrr::map(d$data, enframe)\nd\n\n\n# A tibble: 3 x 2\n  time       data            \n  <date>     <list>          \n1 2009-01-01 <tibble [3 × 2]>\n2 2009-01-02 <tibble [3 × 2]>\n3 2009-01-03 <tibble [3 × 2]>\n\n\n\ntidyr::unnest(d)\n\n\n# A tibble: 9 x 3\n  time       name   value\n  <date>     <chr>  <dbl>\n1 2009-01-01 X     -0.626\n2 2009-01-01 Y      3.19 \n3 2009-01-01 Z      1.95 \n4 2009-01-02 X      0.184\n5 2009-01-02 Y      0.659\n6 2009-01-02 Z      2.95 \n7 2009-01-03 X     -0.836\n8 2009-01-03 Y     -1.64 \n9 2009-01-03 Z      2.30 \n\nDone.\nspread()\nFirst step is the same as gather(). Just nest the data by time.\n\n\nd <- dplyr::group_nest(stocksm, time)\nd\n\n\n# A tibble: 3 x 2\n  time                     data\n  <date>     <list<tibble[,2]>>\n1 2009-01-01            [3 × 2]\n2 2009-01-02            [3 × 2]\n3 2009-01-03            [3 × 2]\n\nThen, deframe() the data.frames. (In practice, we have to fill the missing rows to ensure all data.frames have the same variables.)\n\n\nd$data <- purrr::map(d$data, deframe)\nd\n\n\n# A tibble: 3 x 2\n  time       data     \n  <date>     <list>   \n1 2009-01-01 <dbl [3]>\n2 2009-01-02 <dbl [3]>\n3 2009-01-03 <dbl [3]>\n\nThen, convert the vectors to data.frames.\n\n\nd$data <- purrr::map(d$data, ~ tibble::tibble(!!! .))\nd\n\n\n# A tibble: 3 x 2\n  time       data            \n  <date>     <list>          \n1 2009-01-01 <tibble [1 × 3]>\n2 2009-01-02 <tibble [1 × 3]>\n3 2009-01-03 <tibble [1 × 3]>\n\nLastly, unnest the whole data.\n\n\ntidyr::unnest(d)\n\n\n# A tibble: 3 x 4\n  time            X      Y     Z\n  <date>      <dbl>  <dbl> <dbl>\n1 2009-01-01 -0.626  3.19   1.95\n2 2009-01-02  0.184  0.659  2.95\n3 2009-01-03 -0.836 -1.64   2.30\n\nDone.\nWhat’s next?\nI’m not sure… I roughly believe this can be extended to multi-gather and multi-spread (groups can have multiple vectors and data.frames), but I’m yet to see how different (or same) this is from the current tidyr’s semantics. Again, any feedbacks are welcome!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:17:42+09:00",
    "input_file": {}
  },
  {
    "path": "post/a-tip-to-debug-ggplot2/",
    "title": "A Tip to Debug ggplot2",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2019-01-11",
    "categories": [
      "package development"
    ],
    "contents": "\nSince the tidyverse developer day is near, I share my very very secret technique to debug ggplot2. Though this is a very small thing, hope this helps someone a bit.\nggplot2 is unbreakable!\nYou might want to debug() the methods of Geoms or Stats.\ndebug(GeomPoint$draw_panel)\nBut, this is not effective because the geom_point() generates different instances, so their draw_panel are all different objects (c.f. R6 classes have debug method for this). (edit: [@BrodieGaslam told me I'm wrong](https://twitter.com/BrodieGaslam/status/1083763764682465280). The reason we can’t do debug(GeomPoint$draw_panel) s because $ is overridden and debug(get(\"draw_panel\", GeomPoint)) definitely works.)\nThen what about RStudio’s nice breakpoint features?\n\nUsually, this is enough. But, ggplot2’s ggprotos are not the case. You cannot use breakpoints to dig into them.\n\nHmm… But, no, you don’t need to scratch your head. The solution is pretty simple.\nUse browser()\nYou just need to\nadd browser() on the line where you want to debug, and\nload all (Cmd+Shift+L for Mac, Ctrl+Shift+L for Windows, and C-c C-w l for Emacs/ESS).\n\nThen, you’ll be on debug mode at last!\n\n\nYMMV\nThat’s all for this posts. But, I guess there are many alternative ways to achieve this, and I’m almost sure, at the end of the developer day, I will feel shame to have published this post, which just describes my debug skill is so poor… I’m really looking forward to learning from others. See you there!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:16:57+09:00",
    "input_file": {}
  },
  {
    "path": "post/how-to-convert-a-human-to-waves-by-magick-package/",
    "title": "How To Convert A Human To Waves By Magick Package",
    "description": "",
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-11-23",
    "categories": [
      "ggplot2",
      "magick"
    ],
    "contents": "\nI saw this tweet about Mathematica last year, which naturally urged me to write the R version of this code.\n\n\nMathematicaを使って，シュレーディンガーの顔をこのようなアニメーションにされたユーザの方がいらっしゃいます。コードも掲載されています。https://t.co/IDIzM8Xfy2 pic.twitter.com/ZTIbjtmXBm\n\n— Wolfram Japan (@WolframJapan) June 15, 2017\n\nAt that time, I faild because I didn’t know how to zoom images. But, now I know magick package. Let’s try again…\nZoom images by magick\nWe can enlarge a image by either image_resize(), image_scale(), or image_sample(). I don’t know about the details of the differences, but it seems image_resize() does better for my purpose.\n\n\nlibrary(magick)\n\nrose <- image_convert(image_read(\"rose:\"), \"png\")\n\nroses <- c(\n    image_resize(rose, \"400x\"),\n    image_scale(rose, \"400x\"),\n    image_sample(rose, \"400x\")\n)\n\nimage_append(roses, stack = TRUE)\n\n\n\n\nBut, zooming is not just about resizing; I want to focus on the center of the image as well. To do this, we can use image_crop(). But, it’s our job to calculate the perper offset to centering the image (IIUC, there’s no equivalent of -gravity center in magick package, right??).\nSuppose we want to zoom by 200%. First of all, extract the original width and height.\n\n\ninfo <- image_info(rose)\norig_width <- info$width\norig_height <- info$height\n\n\n\nThen, let’s calculate the offset; to center the image, the offset should be half of the diffrence between the original size and the size you want.\n\n\nwidth <- as.integer(orig_width * 2)\nheight <- as.integer(orig_height * 2)\n\noffset_x <- as.integer((width - orig_width) / 2)\noffset_y <- as.integer((height - orig_height) / 2)\n\n\n\nNow we have enough information to crop the image. To provide these to Imagemagick, we need to learn a bit about Geometry syntax. It’s as simple as:\n<width>x<height>{+-}<xoffset>{+-}<yoffset>\nWe can construct the geometries by sprintf() (use %+d instead of %d when we need explicit plus sign) as follows:\n\n\n(g_resize <- sprintf(\"%dx%d\", width, height))\n\n\n[1] \"140x92\"\n\n(g_crop <- sprintf(\"%dx%d%+d%+d\", orig_width, orig_height, offset_x, offset_y))\n\n\n[1] \"70x46+35+23\"\n\nNow we can zoom\n\n\nrose_zoomed <- rose %>%\n  image_resize(g_resize) %>% \n  image_crop(g_crop)\n\nimage_append(c(rose, rose_zoomed), stack = TRUE)\n\n\n\n\nZoom animatedly\nNow that we know how to zoom, we can create a function to draw rose at the specified zoom level.\n\n\nzoom_rose <- function(zoom = 1) {\n  width <- as.integer(orig_width * zoom)\n  height <- as.integer(orig_height * zoom)\n  \n  offset_x <- as.integer((width - orig_width) / 2)\n  offset_y <- as.integer((height - orig_height) / 2)\n  \n  g_resize <- sprintf(\"%dx%d\", width, height)\n  g_crop <- sprintf(\"%dx%d%+d%+d\", orig_width, orig_height, offset_x, offset_y)\n\n  rose %>%\n    image_resize(g_resize) %>% \n    image_crop(g_crop)\n}\n\nzoom_rose(1)\n\n\n\nzoom_rose(2)\n\n\n\n\nThe function can be applied to the vector of zoom levels by lapply(). Note that, to make the zoom speed looks constant, we need to power the steps.\n\n\nsteps <- 100\nzooms <- 1 + 9 * (0:steps / steps)^2\nimgs <- lapply(zooms, zoom_rose)\n\n\n\nThe list of images can be combined by image_join() and then can be converted to an animation by image_animate()\n\n\nimgs %>%\n  image_join() %>%\n  image_animate(fps = 50)\n\n\n\n\nResult\nAparently, there are a lot of things to explain (expecially about involute of a circle), but it would be a bit too long… Let’s jump to the final version of my code and the result :P\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr, warn.conflicts = FALSE)\n\n# the speed of involute increases uniformly; in order to make the lengths between\n# steps equal, we need to calculate the square root\nresolution_of_involute <- 10000L\nt <- sqrt(seq(0, resolution_of_involute) / resolution_of_involute)\n\ncoil_turns <- 17L\nmax_r <- coil_turns * 2 * pi\n\n# waviness of the coil\nwave_frequency <- 100\nwave_height_base <- pi\n\n# download and read the image\nimg_file <- tempfile(fileext = \".png\")\ndownload.file(\"https://hoxo-m.com/img/team/makiyama.png\", destfile = img_file, mode = \"wb\")\nimg_orig <- image_read(img_file)\n\n# convert to grayscale\nimg_bw <- img_orig %>% \n  image_convert(type = \"grayscale\") %>%\n  image_modulate(brightness = 160) %>% \n  image_contrast(10)\n\n# the width and height of the output\nw <- 320\nh <- 320\n\n# the width and height of the original image\ninfo <- image_info(img_bw)\nw_orig <- info$width\nh_orig <- info$height\n\n# the width and height of the zoomed image\nscale <- 30L\nw_big <- w_orig * scale\nh_big <- h_orig * scale\n\n# zoom image\nimg_bw_big <- image_resize(img_bw, sprintf(\"%dx%d\", w_big, h_big))\n\n# place the small image on the center of the big image\nimg <- image_composite(img_bw_big, img_bw,\n                       offset = sprintf(\"%+d%+d\",\n                                        as.integer((w_big - w_orig) / 2),\n                                        as.integer((h_big - h_orig) / 2)))\n\ndraw_hoxom <- function(rotation = 0, zoom = 1) {\n  # unwavy involute\n  d <- tibble(\n    radius = 2 * pi * t * coil_turns,\n    phi = radius - rotation,\n    .x = cos(phi) + radius * sin(phi),\n    .y = sin(phi) - radius * cos(phi)\n  )\n\n  # crop and resize the image at the specified zoom level\n  g <- sprintf(\"%dx%d%+d%+d\",\n               as.integer(w_big / zoom),\n               as.integer(h_big / zoom),\n               as.integer((w_big - w_big / zoom) / 2),\n               as.integer((h_big - h_big / zoom) / 2))\n  \n  blackness <- img %>%\n    image_crop(g) %>%\n    image_resize(sprintf(\"%dx%d\", w, h)) %>%\n    image_data(\"gray\")\n\n  # calculate which pixel each point falls in\n  x_idx <- as.integer(scales::rescale(d$.x, from = c(-max_r, max_r), to = c(1L, dim(blackness)[2])))\n  y_idx <- as.integer(scales::rescale(d$.y, from = c(-max_r, max_r), to = c(dim(blackness)[3], 1L)))\n  \n  # determine the wave height based on the blackness\n  wave_height <- (255 - as.numeric(blackness[cbind(1, x_idx, y_idx)])) / 256 * wave_height_base\n\n  # wavy involute  \n  d_wavy <- d %>% \n    mutate(\n      x = .x + wave_height * sin(phi * wave_frequency) * sin(phi),\n      y = .y - wave_height * sin(phi * wave_frequency) * cos(phi)\n    )\n  \n  p <- ggplot(d_wavy) +\n    geom_path(aes(x, y)) +\n    theme_minimal() +\n    coord_equal(\n      # 0.85 is for zoom\n      xlim = c(-max_r, max_r) * 0.85,\n      ylim = c(-max_r, max_r) * 0.85\n    ) +\n    theme_void()\n  \n  print(p)\n}\n\n\nimgs <- image_graph(w, h, res = 72)\n\nsteps <- 100\nfor (i in seq_len(steps)) {\n  draw_hoxom(2 * pi * i / steps, 1 + (scale - 1) / steps^2 * i^2)\n}\n\ndev.off()\n\n\npng \n  2 \n\nimage_animate(imgs, fps = 50)\n\n\n\n\nI’m grad I’ve finally proven that I can live without Mathematica!\n\n\n\n",
    "preview": "https://yutani.rbind.io/post/how-to-convert-a-human-to-waves-by-magick-package/images/preview.png",
    "last_modified": "2021-06-05T23:18:26+09:00",
    "input_file": {}
  },
  {
    "path": "post/quote-while-the-promise-is-hot/",
    "title": "Quote While the Promise Is Hot!",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-10-18",
    "categories": [
      "tidyeval",
      "tidyverse"
    ],
    "contents": "\nSuppose we want to quote x when x is not NULL. The naive implementation would be like below. Here, y is for comparison. Do you understand why x and y are quoted differently?\nquote_x_and_y <- function(x, y) {\n  if (is.null(x)) {\n    stop(\"x is NULL!\", call. = FALSE)\n  }\n  \n  x <- rlang::enquo(x)\n  y <- rlang::enquo(y)\n  \n  list(x, y)\n}\n\nx <- y <- 1\n\nquote_x_and_y(x, y)\n#> [[1]]\n#> <quosure>\n#>   expr: ^1\n#>   env:  empty\n#> \n#> [[2]]\n#> <quosure>\n#>   expr: ^y\n#>   env:  global\nThis is because x is evaluated when is.null() is called before quoting, whereas y is intact. Lionel Henry, the tidyeval super hero, answered my qustion on RStudio Community:\n\nA forced promise can no longer be captured correctly because it no longer carries an environment.\n\nThis means we must not touch arguments before quoting. Instead, quote first and check the expression inside quosure by rlang::quo_is_*().\nquote_x_and_y2 <- function(x, y) {\n  x <- rlang::enquo(x)\n  y <- rlang::enquo(y)\n  \n  if (rlang::quo_is_null(x)) {\n    stop(\"x is NULL!\", call. = FALSE)\n  }\n  \n  list(x, y)\n}\n\nquote_x_and_y2(x, y)\n#> [[1]]\n#> <quosure>\n#>   expr: ^x\n#>   env:  global\n#> \n#> [[2]]\n#> <quosure>\n#>   expr: ^y\n#>   env:  global\nFor more complex checking, we may need to extract the expression from the quosure by rlang::quo_get_expr().\nquote_x_and_y_wont_stop <- function(x, y) {\n  x <- rlang::enquo(x)\n  y <- rlang::enquo(y)\n\n  x_expr <- rlang::quo_get_expr(x)  \n  if (rlang::call_name(x) %in% \"stop\") {\n    message(\"Nothing can stop me!\\n\")\n  }\n  \n  list(x, y)\n}\n\nquote_x_and_y_wont_stop(stop(\"foo\"), \"bar\")\n#> Nothing can stop me!\n#> [[1]]\n#> <quosure>\n#>   expr: ^stop(\"foo\")\n#>   env:  global\n#> \n#> [[2]]\n#> <quosure>\n#>   expr: ^\"bar\"\n#>   env:  empty\nAnyway, keep in mind to use enquo() (or ensym()) at the very beginning of the function. Quote while the promise is hot.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:19:11+09:00",
    "input_file": {}
  },
  {
    "path": "post/geom-sf-text-and-geom-sf-label-are-coming/",
    "title": "geom_sf_text() and geom_sf_label() Are Coming!",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-10-10",
    "categories": [
      "tidyverse",
      "ggplot2"
    ],
    "contents": "\nggplot2 v3.1.0 will be released soon (hopefully), so let me do a spoiler about a small feature I implemented, geom_sf_label() and geom_sf_text().\nHow can we add label/text with geom_sf()?\ngeom_sf() is one of the most exciting features introduced in ggplot2 v3.0.0. It magically allows us to plot sf objects according to their geometries’ shapes (polygons, lines and points).\nBut, for plotting them as some other shapes than the original ones, we cannot rely on geom_sf() so it needs a bit of data transformation beforehand. Suppose we want to add text on each geometry, we need to\ncalculate the proper point to add text/labels per geometry by some function like sf::st_centroid() and sf::st_point_on_surface(),\nretrieve the coordinates from the calculated points by sf::st_coordinates(), and\nuse geom_text() or geom_label() with the coordinates\nThe code for this would be like below:\n\n\nlibrary(ggplot2)\n\nnc <- sf::st_read(system.file(\"shape/nc.shp\", package = \"sf\"), quiet = TRUE)\n\n# use only first three elements\nnc3 <- nc[1:3, ]\n\n# choose a point on the surface of each geometry\nnc3_points <- sf::st_point_on_surface(nc3)\n\n# retrieve the coordinates\nnc3_coords <- as.data.frame(sf::st_coordinates(nc3_points))\nnc3_coords$NAME <- nc3$NAME\n\nnc3_coords\n\n\n          X        Y      NAME\n1 -81.49496 36.42112      Ashe\n2 -81.13241 36.47396 Alleghany\n3 -80.69280 36.38828     Surry\n\nggplot() +\n  geom_sf(data = nc3, aes(fill = AREA)) +\n  geom_text(data = nc3_coords, aes(X, Y, label = NAME), colour = \"white\")\n\n\n\n\nPhew, this seems not so difficult, but I feel the code is a bit too long…\ngeom_sf_label() and geom_sf_text()\nFor this purpose, upcoming ggplot2 v3.1.0 provides two new geoms, geom_sf_text() and geom_sf_label(). The code equivalent to above can be written as:\n\n\n# texts and labels\np <- ggplot(nc3) +\n  geom_sf(aes(fill = AREA))\n\np + geom_sf_text(aes(label = NAME), colour = \"white\")\n\n\n\n\nFor labels, use geom_sf_label():\n\n\np + geom_sf_label(aes(label = NAME))\n\n\n\n\nProtip: stat_sf_coordinates()\nUnder the hood, a Stat called stat_sf_coordinates() does the necessary calculations. If you are an expert of ggplot2, please play with this by combining with other Geoms. As an example, here’s a preliminary version of geom_sf_label_repel() (which I want to implement next…):\n\n\nggplot(nc) +\n  geom_sf() +\n  ggrepel::geom_label_repel(\n    data = nc[c(1:3, 10:14), ],\n    aes(label = NAME, geometry = geometry),\n    stat = \"sf_coordinates\",\n    min.segment.length = 0,\n    colour = \"magenta\",\n    segment.colour = \"magenta\"\n  )\n\n\n\n\nFor other cool NEWS of ggplot2 v3.1.0, please read the NEWS.md :)\n\n\n\n",
    "preview": "post/geom-sf-text-and-geom-sf-label-are-coming/2018-10-10-geom-sf-text-and-geom-sf-label-are-coming_files/figure-html5/geom_sf_label_repel-1.png",
    "last_modified": "2021-06-05T23:17:58+09:00",
    "input_file": {}
  },
  {
    "path": "post/double-dispatch-of-s3-method/",
    "title": "Double dispatch of S3 method",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-09-17",
    "categories": [
      "R internal"
    ],
    "contents": "\nWhen I tried to define an S3 class that contains multiple ggplot objects, I’ve faced the lessor-know mechanism of S3 method dispatch, double dispatch.\nProblem\nTake a look at this example. manyplot class contains many plots, and displays them nicely when printted.\n\n\nlibrary(ggplot2)\n\nset.seed(100)\nd1 <- data.frame(x = 1:100, y = cumsum(runif(100)))\nd2 <- data.frame(x = 1:100, y = cumsum(runif(100)))\n\nplot_all <- function(...) {\n  l <- lapply(list(...), function(d) ggplot(d, aes(x, y)) + geom_line())\n  l <- unname(l)\n  class(l) <- \"manyplot\"\n  l\n}\n\nprint.manyplot <- function(x, ...) {\n  do.call(gridExtra::grid.arrange, x)\n}\n\np <- plot_all(d1, d2)\np\n\n\n\n\nSo far, so good.\nNext, I want to define + method, so that I can customize the plots just as I do with usual ggplot2.\n\n\n`+.manyplot` <- function(e1, e2) {\n  l <- lapply(e1, function(x) x + e2)\n  class(l) <- \"manyplot\"\n  l\n}\n\n\n\nBut, this won’t work…\n\n\np + theme_bw()\n\n\nError in p + theme_bw(): non-numeric argument to binary operator\n\nWhat’s this cryptic error? To understand what happened, we need to dive into the concept of S3’s “double dispatch”\nDouble dispatch?\nUsually, S3’s method dispatch depends only on the type of first argument. But, in cases of some infix operators like + and *, it uses both of their arguments; this is called double dispatch.\nWhy is this needed? According to Advanced R:\n\nThis is necessary to preserve the commutative property of many operators, i.e. a + b should equal b + a.\n\nTo ensure this, if both a and b are S3 objects, the method chosen in a + b can be (c.f. how do_arith() works with S3 objects):\nDoes a have an S3 method?\nDoes b have an S3 method?\nAre the methods same?\nWhet method is chosen?\nyes\nyes\nyes\na’s method or b’s method (they are the same)\nyes\nyes\nno\ninternal method\nyes\nno\n-\na’s method\nno\nyes\n-\nb’s method\nno\nno\n-\ninternal method\nHere’s examples to show them clearly:\n\n\nfoo <- function(x) structure(x, class = \"foo\")\n`+.foo` <- function(e1, e2) message(\"foo!\")\n\nbar <- function(x) structure(x, class = \"bar\")\n`+.bar` <- function(e1, e2) message(\"bar?\")\n\n# both have the same S3 method\nfoo(1) + foo(1)\n\n\nNULL\n\n# both have different S3 methods\nfoo(1) + bar(1)\n\n\n[1] 2\nattr(,\"class\")\n[1] \"foo\"\n\n# `a` has a method, and `b` doesn't\nfoo() + 1\n\n\nError in structure(x, class = \"foo\"): argument \"x\" is missing, with no default\n\n# `b` has a method, and `a` doesn't\n1 + foo()\n\n\nError in structure(x, class = \"foo\"): argument \"x\" is missing, with no default\n\n# both don't have methods\nrm(`+.foo`)\nfoo(1) + foo(1)\n\n\n[1] 2\nattr(,\"class\")\n[1] \"foo\"\n\nExplanation\nSo, now it’s clear to our eyes what happened in the code below; they have different methods (+.manyplot and +.gg) so it falled back to internal method. But, because fundamentally they are list, the internal mechanism refused to add these two objects…\n\n\np + theme_bw()\n\n\n\nHow can I overcome this?\nHadley says ggplot2 might eventually end up using the double-dispatch approach in vctrs. So, we can wait for the last hope.\nIf you cannot wait, use S4. S4 can naturally do double dispatch because their method dispatch depends on the whole combination of types of the arguments.\n\n\n\n",
    "preview": "post/double-dispatch-of-s3-method/2018-09-17-double-dispatch-of-s3-method_files/figure-html5/define-ggplot-1.png",
    "last_modified": "2021-06-05T23:17:13+09:00",
    "input_file": {}
  },
  {
    "path": "post/gghighlight-0-1-0-is-released/",
    "title": "gghighlight 0.1.0 Is Released!",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-07-04",
    "categories": [
      "ggplot2",
      "gghighlight"
    ],
    "contents": "\ngghighlight 0.1.0 is on CRAN now!\nNew features\nAs I’ve introduced on the previous post, gghighlight now can highlight any Geoms with gghighlight(). Since this function supersedes the previous functions, gghighlight_line() and gghighlight_point() are now deprecated.\n\nA Vignette\nOne more small news is, gghighlight got an introductory vignette. This is basically the shorter version of the previous post:\nIntroduction to gghighlight\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-05-30T23:52:24+09:00",
    "input_file": {}
  },
  {
    "path": "post/2018-06-16-re-intro-to-gghighlight/",
    "title": "Re-introduction to gghighlight: Highlight ggplot2 with Predicates",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-06-16",
    "categories": [
      "ggplot2",
      "gghighlight"
    ],
    "contents": "\nHalf a year ago, I’ve introduced gghighlight package. I didn’t expect so much R people get interested in my package. Thanks for your attention!\nBut, please forget about that gghighlight; gghighlight has become far more powerful and simple! So, let me re-introduce about gghighlight.\n(Note that this version of gghighlight is not yet on CRAN at the time of this writing. Please install by devtools::install_github(\"yutannihilation/gghighlight\") for the time being)\nMotivation\ndplyr has filter()\nWhat do you do when you explore a data that is too large to print?\n\n\nlibrary(dplyr, warn.conflicts = FALSE)\n\nbig_data %>%\n  group_by(some_key) %>%\n  summarise(some_agg = some_func(some_column))\n# Opps, the result is too large!\n\n\n\ndplyr’s filter() is the Swiss army knife for this, which enables us to narrow down the data. One nice thing of this function is that it can be inserted to any steps in the chain of %>%, so we don’t need to rewrite the entire code.\n\n\nbig_data %>%\n  # OK, let's filter the data\n  filter(some_column > some_value) %>%\n  group_by(some_key) %>%\n  summarise(some_agg = some_func(some_column))\n\n\n\nggplot2?\nOK, good. But, what about ggplot2?\nFor a data that has too many series, it is almost impossible to identify a series by its colour as their differences are so subtle.\n\n\nlibrary(tidyverse)\n\nset.seed(2)\nd <- map_dfr(\n  letters,\n  ~ data.frame(\n      idx = 1:400,\n      value = cumsum(runif(400, -1, 1)),\n      type = .,\n      flag = sample(c(TRUE, FALSE), size = 400, replace = TRUE),\n      stringsAsFactors = FALSE\n    )\n)\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type))\n\n\n\n\nOf course, I can use dplyr’s filter() here as well.\n\n\nlibrary(dplyr, warn.conflicts = FALSE)\n\nd_filtered <- d %>%\n  group_by(type) %>% \n  filter(max(value) > 20) %>%\n  ungroup()\n\nggplot(d_filtered) +\n  geom_line(aes(idx, value, colour = type))\n\n\n\n\nBut, it seems not so handy. For example, what if I want to change the threshold in predicate (max(value) > 20) and highlight other series as well? It’s a bit tiresome to type all the code above again every time I replace 20 with some other value…\nSo, I want filter() for ggplot2. This is my initial impulse to create gghighlight.\nHighlighting is better than filtering\nIn my understanding, one of the main purposes of visualization is to get the overview of a data. In this sense, it may not be good to simply filter out the unmatched data because the plot loose its context then. It’s better to keep the unimportant data as grayed-out lines. Here comes the need for highlighting, like this:\n\n\nggplot(d_filtered) +\n  geom_line(aes(idx, value, group = type), data = d, colour = alpha(\"grey\", 0.7)) +\n  geom_line(aes(idx, value, colour = type))\n\n\n\n\nThis looks nicer! So, now, my motivation has changed a bit; I want a function that highlights the important parts of a data, instead of filtering out the unimportant parts.\n(If you are interested in the more details behind the idea of highlighting, you may find this post useful: Anatomy of gghighlight.)\ngghighlight()\nHere is my answer, gghighlight():\n\n\nlibrary(gghighlight)\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type)) +\n  gghighlight(max(value) > 20)\n\n\n\n\nLike filtering data with filter(), you can highlight the data by just adding gghighlight().\nJust like filter(), you can specify as many predicates as you like. For example, the following code highlights the data that satisfies both max(value) > 15 and mean(flag) > 0.55.\n\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type)) +\n  gghighlight(max(value) > 15, mean(flag) > 0.55)\n\n\n\n\nCustomization\nAs adding gghighlight() results in a ggplot object, it is fully customizable just as we usually do with ggplot2 like custom themes.\n\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type)) +\n  gghighlight(max(value) > 19) +\n  theme_minimal()\n\n\n\n\nThe plot also can be facetted:\n\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type)) +\n  gghighlight(max(value) > 19) +\n  theme_minimal() +\n  facet_wrap(~ type)\n\n\n\n\nGeoms\ngghighlight() can highlight almost every geoms. Here are some examples.\nBar\ngghighlight() can highlight bars.\n\n\np <- ggplot(iris, aes(Sepal.Length, fill = Species)) +\n  geom_histogram() +\n  gghighlight()\n\np\n\n\n\n\nYou may wonder if this is really highlighted. Yes, it is. But, the unhighlighted bars are all overwritten by the highlighted bars. This seems not so useful, until you see the fecetted version:\n\n\np + facet_wrap(~ Species)\n\n\n\n\nPoint\nAs I explained in Anatomy of gghighlight, lines and points typically have different semantics (group-wise or not). But, in most cases, you don’t need to be careful about the difference with gghighlight() because it automatically picks the right way of calculation.\n\n\nset.seed(10)\nd2 <- dplyr::sample_n(d, 20)\n\nggplot(d2, aes(idx, value)) +\n  geom_point() +\n  gghighlight(value > 0, label_key = type)\n\n\n\n\nMore precisely, gghighlight() takes the following strategy:\nCalculate the group IDs from mapping.\nIf group exists, use it.\nOtherwise, assign the group IDs based on the combination of the values of discrete variables.\n\nIf the group IDs exists, evaluate the predicates in a grouped manner.\nIf the group IDs doesn’t exist or the grouped calculation fails, evaluate the predicates in an ungrouped manner.\nNote that, in this case, label_key = type is needed to show labels because gghighlights() chooses a discrete variable from the mapping, but aes(idx, value) consists of only continuous variables.\nSf\nFor the proof of gghighlight’s capability, here’s highlighted geom_sf():\n\n\nnc <- sf::st_read(system.file(\"shape/nc.shp\", package = \"sf\"), quiet = TRUE)\n\nggplot(nc) +\n  geom_sf(aes(fill = AREA)) +\n  gghighlight(grepl(\"^[A-C]\", NAME)) +\n  ggtitle(\"Polygons whose names start with A-C are highlighted!\")\n\n\n\n\n(Exceptions)\nI’ve written “gghighlight() can highlight almost every geoms.” I mean, there are some exceptions that gghighlight can not handle. But, I think I’m aware of only few of these. So, please let me know if you see counter-intuitive results or errors via GitHub or Twitter or SO!\nNon-logical predicate\nTo construct a predicate expression like bellow, we need to determine a threshold (in this example, 20). But it is difficult to choose a nice one before we draw plots.\n\n\nmax(value) > 20\n\n\n\nSo, gghighlight() allows predicates that return numeric (or character) results. The values are used for sorting data and the top max_highlight of rows/groups are highlighted:\n\n\nggplot(d, aes(idx, value, colour = type)) +\n  geom_line() +\n  gghighlight(max(value), max_highlight = 5L)\n\n\n\n\nBackward-compatibility\ngghighlight_point() and gghighlight_line() are here to stay for some time, but they will be deprecated in favor of gghighlight(). The design of them was due to the limitation of extendability of ggplot’s + operator, so it was not what it should be. Please consider using gghighlight() instead.\nCaveats\ngghighlight is good to explore data by changing a threshold little by little. But, the internals are not so efficient, as it does almost the same calculation every time you execute gghighlight(), which may get slower when it works with larger data. Consider doing this by using vanilla dplyr to filter data.\nAlternative\nFWIW, here’s a different approach of highlighting ggplot2 by atusy. While my package modifies the clones of the existing layers, ggAtusy package modifies ggproto and create a new function that creates layers. This approach seems clean and simple, whereas my code is full of tweaks and some kind of black magics…\nhttps://github.com/atusy/ggAtusy/blob/master/R/gghl.R\nSummary\ngghighlight package has become cool. Please try!\nBug reports or feature requests are welcome! -> https://github.com/yutannihilation/gghighlight/issues\n\n\n\n",
    "preview": "post/2018-06-16-re-intro-to-gghighlight/2018-06-16-re-intro-to-gghighlight_files/figure-html5/numeric-highlight-1.png",
    "last_modified": "2021-06-05T23:16:17+09:00",
    "input_file": {}
  },
  {
    "path": "post/2018-06-09-plot-osm-tiles/",
    "title": "Plot geom_sf() On OpenStreetMap Tiles",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-06-09",
    "categories": [
      "ggplot2",
      "GIS"
    ],
    "contents": "\nmapview is a very nice package to explore an sf object. It can overlay sf object on the map images:\n\n\nnc <- sf::read_sf(system.file(\"shape/nc.shp\", package=\"sf\"))\n\n# mapview::mapview(nc)\n\n\n\nBut, how can I do this with ggplot2? (My friend told me mapview::mapshot() can generate a PNG, but I want to do this with ggplot2!)\nRTFM\nBefore anything, I need to read Tile Usage Policy to use the OpenStreetMap tiles. For “Requirements” section, this is important:\n\nClearly display license attribution.\n\nAccording to Copyright and License, it’s so simple as just adding this caption to my plots:\n\n\nlabs(caption = \"\\U00a9 OpenStreetMap contributors\")\n\n\n\nFor “Technical Usage Requirements” section, I have to read this more carefully. Let’s look at the requirements one by one.\n\nValid HTTP User-Agent identifying application. Faking another app’s User-Agent WILL get you blocked.\n\nOh, it seems I need to add User-Agent header. OK, let’s invent some nice name… If I use httr::GET(), the code will probably like this:\n\n\nGET(\n  \"https://...\",\n  add_headers(`User-Agent` = \"Yutani's blog post\")\n)\n\n\n\n\nIf known, a valid HTTP Referer.\n\nI don’t have Referers, so I skip this.\n\nDO NOT send no-cache headers. (“Cache-Control: no-cache”, “Pragma: no-cache” etc.)\n\nI do nothing other than swearing I’ll never use this header.\n\nCache Tile downloads locally according to HTTP Expiry Header, alternatively a minimum of 7 days.\n\nAh, this is important. Let’s implement later.\n\nMaximum of 2 download threads. (Unmodified web browsers’ download thread limits are acceptable.)\n\nFortunately, I’m not good at parallelism, so this is fine.\nGet Tile URLs\nAccording to Slippy map tilenames, the URL of a tile follows this format:\nhttps://[abc].tile.openstreetmap.org/zoom/x/y.png \nI have to fill these four parts:\n[abc]\nzoom\nx\ny\nLet’s look at these one by one.\n[abc]\n[abc] means there are three domains; a.tile.openstreetmap.org, b.tile.openstreetmap.org, c.tile.openstreetmap.org. But, why? It says:\n\nBrowser-based applications can thus request multiple tiles from multiple subdomains faster than from one subdomain.\n\nSo, as I’m not browser-based, I can choose arbitrary one.\nzoom\nZoom parameter is an integer number from 0 to 19. If zoom is 0, there’s only one tile. Likewise 2 x 2 tiles for zoom 1, 4 x 4 tiles for zoom 2, and so on. Then, which one should I choose? This can be roughly determined based on the size of the bbox (boundary box) of the sf object.\n\n\n# get the bbox\nb <- sf::st_bbox(nc)\nb\n\n\n     xmin      ymin      xmax      ymax \n-84.32385  33.88199 -75.45698  36.58965 \n\n# calculate the lengths of x and y of the bbox\nx_len <- b[\"xmax\"] - b[\"xmin\"]\ny_len <- b[\"ymax\"] - b[\"ymin\"]\n\n# calculate the minimum zoom level that is smaller than the lengths\nx_zoom <- sum(x_len < 360 / 2^(0:19)) - 1\ny_zoom <- sum(y_len < 170.1022 / 2^(0:19)) - 1\n\nzoom <- min(x_zoom, y_zoom)\nzoom\n\n\n[1] 5\n\nBut, since the tile is so small as 256 × 256 pixel, it’s often better to zoom more.\n\n\nzoom <- zoom + 2\n\n\n\n(I’m not sure how to do this correctly, I guess the zoom level should be determined by the size of the plot canvas, not the bbox.)\nx and y\nA pair of x and y represents the location of a tile. x corresponds to longitude, y to latitude. If the zoom is given, I can convert longitudes and latitudes to x and y according to the pseudo code on OpenStreetMap’s wiki:\n\n\nsec <- function(x) {\n  1 / cos(x)\n}\n\nlonlat2xy <- function(lat_deg, lon_deg, zoom) {\n  n <- 2^zoom\n\n  x <- (n * (lat_deg + 180)) %/% 360\n  lon_rad <- lon_deg * pi / 180\n  y <- (n * (1 - log(tan(lon_rad) + sec(lon_rad)) / pi)) %/% 2\n\n  list(x = x, y = y)\n}\n\n\n\nBut, how can I find the set of tiles which covers the whole bbox?\n\n\nlibrary(ggplot2)\n\np <- ggplot(nc) +\n  geom_sf() +\n  annotate(\"rect\", xmin = b[\"xmin\"], xmax = b[\"xmax\"], ymin = b[\"ymin\"], ymax = b[\"ymax\"],\n           colour = alpha(\"red\", 0.4), fill = \"transparent\", linetype = \"dashed\", size = 1.2)\np\n\n\n\n\nThis problem can be simplified; I can focus only two corners, the north-west and the south-east. If I calculate which tiles of x and y those two points fall in, I can find the rest of the tiles by filling the sequences of x and y between these two tiles.\n\n\ncorners <- expand.grid(x = b[c(1, 3)], y = b[c(2, 4)])\n\np +\n  geom_point(aes(x, y), corners[2:3,], colour = \"red\", size = 5)\n\n\n\n\nHere’s the tiles:\n\n\nxy <- lonlat2xy(b[c(\"xmin\", \"xmax\")], b[c(\"ymin\", \"ymax\")], zoom)\n\ntiles <- expand.grid(x = seq(xy$x[\"xmin\"], xy$x[\"xmax\"]),\n                     y = seq(xy$y[\"ymin\"], xy$y[\"ymax\"]))\n\ntiles\n\n\n   x  y\n1 34 51\n2 35 51\n3 36 51\n4 37 51\n5 34 50\n6 35 50\n7 36 50\n8 37 50\n\nTile URLs\nFrom the results above, I can yield the URLs of the tiles:\n\n\nurls <- sprintf(\"https://a.tile.openstreetmap.org/%d/%d/%d.png\", zoom, tiles$x, tiles$y)\nurls\n\n\n[1] \"https://a.tile.openstreetmap.org/7/34/51.png\"\n[2] \"https://a.tile.openstreetmap.org/7/35/51.png\"\n[3] \"https://a.tile.openstreetmap.org/7/36/51.png\"\n[4] \"https://a.tile.openstreetmap.org/7/37/51.png\"\n[5] \"https://a.tile.openstreetmap.org/7/34/50.png\"\n[6] \"https://a.tile.openstreetmap.org/7/35/50.png\"\n[7] \"https://a.tile.openstreetmap.org/7/36/50.png\"\n[8] \"https://a.tile.openstreetmap.org/7/37/50.png\"\n\nOK, now I can download them. But, before that, let’s confirm that the tiles really cover the expected area.\nTile positions\nTo plot these tiles, I calculate the north-west corner of a tile by the following code (the pseudo code for this is also found on the wiki):\n\n\nxy2lonlat <- function(x, y, zoom) {\n  n <- 2^zoom\n\n  lon_deg <- x / n * 360.0 - 180.0\n  lat_rad <- atan(sinh(pi * (1 - 2 * y / n)))\n  lat_deg <- lat_rad * 180.0 / pi\n\n  list(lon_deg = lon_deg, lat_deg = lat_deg)\n}\n\n\n\nThen, south-east corners can be also calculated easily. Let’s calculate the both corners and bind them to a data.frame.\n\n\nlibrary(purrr)\nlibrary(dplyr, warn.conflicts = FALSE)\n\nnw_corners <- pmap_dfr(tiles, xy2lonlat, zoom = zoom)\n# add 1 to x and y to get the south-east corners\nse_corners <- pmap_dfr(mutate_all(tiles, `+`, 1), xy2lonlat, zoom = zoom)\n\nnames(nw_corners) <- c(\"xmin\", \"ymax\")\nnames(se_corners) <- c(\"xmax\", \"ymin\")\n\ntile_positions <- bind_cols(nw_corners, se_corners)\ntile_positions\n\n\n# A tibble: 8 x 4\n   xmin  ymax  xmax  ymin\n  <dbl> <dbl> <dbl> <dbl>\n1 -84.4  34.3 -81.6  32.0\n2 -81.6  34.3 -78.8  32.0\n3 -78.8  34.3 -75.9  32.0\n4 -75.9  34.3 -73.1  32.0\n5 -84.4  36.6 -81.6  34.3\n6 -81.6  36.6 -78.8  34.3\n7 -78.8  36.6 -75.9  34.3\n8 -75.9  36.6 -73.1  34.3\n\nNow I can plot the empty tiles as below:\n\n\np +\n  geom_point(aes(x, y), corners[2:3,], colour = \"red\", size = 5) +\n  geom_rect(data = tile_positions,\n            aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n            colour = \"blue\", fill = \"transparent\")\n\n\n\n\nYay, confirmed! Let’s proceed to the next step.\nGet tile data\nIf I just get the response from a URL, httr::GET() is handy. But, this time, for the requirement of caching, I have to save the responses to disk first. So, I use curl::curl_download() here.\nNote that PNG data can be read into R session by png::readPNG().\n\n\nget_tile <- function(url) {\n  # build a local path\n  path <- stringr::str_extract(url, \"/\\\\d+/\\\\d+/\\\\d+.png\")\n  local_png <- here::here(file.path(\"data\", \"osm-tiles\", path))\n\n  if (!file.exists(local_png)) {\n    dir.create(dirname(local_png), showWarnings = FALSE, recursive = TRUE)\n    \n    # add header\n    h <- curl::new_handle()\n    curl::handle_setheaders(h, `User-Agent` = \"Yutani's blog post\")\n    \n    curl::curl_download(url, destfile = local_png)\n  }\n\n  png::readPNG(local_png)\n}\n\n\n\nThen, let’s get all tiles.\n\n\npngs <- map(urls, get_tile)\n\n\n\nPlot tiles\nTo plot tiles, I use annotation_raster(), whose necessary arguments are:\nraster\nxmin\nxmax\nymin\nymax\nThe first one is pngs and the others are contained in tile_positions. So, let’s combine them so that I can use pmap().\n\n\nargs <- tile_positions %>%\n  mutate(raster = pngs)\n\nargs\n\n\n# A tibble: 8 x 5\n   xmin  ymax  xmax  ymin raster               \n  <dbl> <dbl> <dbl> <dbl> <list>               \n1 -84.4  34.3 -81.6  32.0 <dbl [256 × 256 × 3]>\n2 -81.6  34.3 -78.8  32.0 <dbl [256 × 256 × 3]>\n3 -78.8  34.3 -75.9  32.0 <dbl [256 × 256 × 3]>\n4 -75.9  34.3 -73.1  32.0 <dbl [256 × 256 × 3]>\n5 -84.4  36.6 -81.6  34.3 <dbl [256 × 256 × 3]>\n6 -81.6  36.6 -78.8  34.3 <dbl [256 × 256 × 3]>\n7 -78.8  36.6 -75.9  34.3 <dbl [256 × 256 × 3]>\n8 -75.9  36.6 -73.1  34.3 <dbl [256 × 256 × 3]>\n\nNow I can plot tiles at last.\n\n\nggplot(nc) +\n  pmap(args, annotation_raster, interpolate = TRUE) +\n  geom_sf(fill = alpha(\"red\", 0.3)) +\n  # don't forget the license notice!\n  labs(caption = \"\\U00a9 OpenStreetMap contributors\") +\n  theme_minimal()\n\n\n\n\nDone!\nBut, I didn’t expect the code would be this long… Maybe I need to create a package for this.\nCaveats\nNote that, I didn’t care about the CRS because nc’s CRS is fortunately EPSG 3857, which OpenStreetMap uses. If the sf object I want to plot has the different CRS, there may be a bit more to consider (and I don’t understand the CRS well…).\nUpdate:\nSorry, I was wrong… nc’s CRS is EPSG 4267 and OpenStreetMap tiles use EPSG 4326. Thanks Edzer for pointing this out!\n\n\nsf::st_crs(nc)\n\n\nCoordinate Reference System:\n  User input: NAD27 \n  wkt:\nGEOGCRS[\"NAD27\",\n    DATUM[\"North American Datum 1927\",\n        ELLIPSOID[\"Clarke 1866\",6378206.4,294.978698213898,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4267]]\n\nSo, I should have converted nc to the CRS first.\n\n\nnc_4326 <- sf::st_transform(nc, 4326)\n\n\n\nFortunately, the difference between EPSG 4267 and EPSG 4326 is rather negligible for this scale, so the result map should look almost same if I used nc_4326 instead of nc. Here’s the difference (can you see there’s a little red colors?):\n\n\nnc_4326_not_transformed <- sf::`st_crs<-`(nc, 4326)\n\nggplot() +\n  geom_sf(data = nc_4326_not_transformed, fill = \"transparent\", colour = \"red\") +\n  geom_sf(data = nc_4326, fill = \"transparent\", colour = \"blue\") +\n  theme_minimal()\n\n\n\n\n\n\n\n",
    "preview": "post/2018-06-09-plot-osm-tiles/2018-06-09-plot-osm-tiles_files/figure-html5/plot-1.png",
    "last_modified": "2021-06-05T23:15:58+09:00",
    "input_file": {}
  },
  {
    "path": "post/2018-06-03-anatomy-of-gghighlight/",
    "title": "Anatomy of gghighlight",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-06-03",
    "categories": [
      "gghighlight",
      "ggplot2"
    ],
    "contents": "\nI’m overhauling my gghighlight package toward the upcoming release of ggplot2 2.3.0. I think I will introduce about the new gghighlight() soon, but before that, I want to write out the ideas behind gghighlight.\nNote that what I’ll write here contains few new things, as the basic idea is already covered by this great post:\nPlotting background data for groups with ggplot2\nMy post is mainly for organizing my thought, yet I hope someone find this useful :)\n\n\n# tweak for plotting\nknit_print.ggplot <- function(x, ...) {\n  x <- x  +\n    theme_minimal() +\n    scale_x_continuous(expand = expand_scale(mult = 0.5)) +\n    scale_y_continuous(expand = expand_scale(mult = 0.2))\n  ggplot2:::print.ggplot(x, ...)\n}\n\n\n\nData\nSuppose we have this data:\n\nx\ny\ntype\nvalue\n3\n3\na\n0\n8\n3\na\n1\n13\n3\na\n0\n2\n2\nb\n0\n7\n2\nb\n10\n12\n2\nb\n10\n1\n1\nc\n10\n6\n1\nc\n20\n11\n1\nc\n0\n\nSimple plot\nIf we plot the data very simply, the code would be like this:\n\n\nlibrary(tidyverse)\n\nggplot(d, aes(x, y, colour = type)) +\n  geom_point(size = 10)\n\n\n\n\nHighlighted plot\nNow, what if we want to highlight only the points of records whose type are \"b\"?\nWe need two layers:\nunhighlighted layer\nhighlighted layer\nCreate an unhighlighted layer\nAn unhighlighted layer is the colorless version of the above points with the same data. To create this, we can simply remove colour from aes() and specify a static colour \"grey\". I call this operation as bleach.\n\n\nbleached_layer <- geom_point(data = d, aes(x, y),\n                             size = 10, colour = \"grey\")\n\n\n\nIf we plot this, the result would be below:\n\n\nggplot() +\n  bleached_layer\n\n\n\n\nCreate a highlighted layer\nA highlighted layer is the fewer-data version of the above points with (not necessarily the same) colors. To create this, we need some data manipulation. Let’s filter the data.\n\n\nd_sieved <- filter(d, type == \"b\")\n\n\n\nThen the layer we want can be created like below. I call this operation as sieve (filter might be a better word, but I wanted to choose another word than dplyr’s verbs to avoid confusion).\n\n\nsieved_layer <- geom_point(data = d_sieved, aes(x, y, colour = type),\n                           size = 10)\n\n\n\nIf we plot this, the result would be below:\n\n\nggplot() +\n  sieved_layer\n\n\n\n\nJoin the two layers\nNow we can draw the highlighted version of the plot as below:\n\n\nggplot() +\n  bleached_layer +\n  sieved_layer\n\n\n\n\n“by point” vs “by group”\nSo far, so good. Then, let’s consider a bit about the case when the geom is not point, but line.\nWhile points can be plotted one by one, lines cannot be drawn without the relationship between points. For example, haven’t you experienced an unexpected zigzag line?\n\n\nggplot(d, aes(x, y)) +\n  geom_line(size = 3)\n\n\n\n\nLines need group variable, which indicates the series of data points.\n\n\nggplot(d, aes(x, y, group = type)) +\n  geom_line(size = 3)\n\n\n\n\nNote that group doesn’t need to be declared explicitly, as ggplot2 infers the groups from the specified variables. More precisely, it calculates group IDs based on the combination of discrete variables here. So, usually, specifying a discrete variable on colour or fill is enough.\n\n\nggplot(d, aes(x, y, colour = type)) +\n  geom_line(size = 3)\n\n\n\n\nAnyway, lines need groups. Accordingly, we need to consider the group when we sieve the data. Otherwise, the lines will be incomplete as this example:\n\n\n# data whose values are >=10\nd_sieved2 <- filter(d, value >= 10)\n\nggplot() +\n  geom_line(data = d, aes(x, y, group = type), size = 3, colour = \"grey\") +\n  geom_line(data = d_sieved2, aes(x, y, colour = type), size = 3)\n\n\n\n\nSo, the correct way of doing this is to use group_by() and some aggregate functions like max() so that the calculations are done by group.\n\n\n# data series whose max values are >=10\nd_sieved3 <- d %>%\n  group_by(type) %>% \n  filter(max(value) >= 10)\n\nggplot() +\n  geom_line(data = d, aes(x, y, group = type), size = 3, colour = \"grey\") +\n  geom_line(data = d_sieved3, aes(x, y, colour = type), size = 3)\n\n\n\n\nPrevent unhighlighted layer from facetted\nNext topic is facetting. Let’s naively facet the plot above.\n\n\nggplot() +\n  geom_line(data = d, aes(x, y, group = type), size = 3, colour = \"grey\") +\n  geom_line(data = d_sieved3, aes(x, y, colour = type), size = 3) +\n  facet_wrap(~ type)\n\n\n\n\nHmm…, unhighlighted lines are facetted. But, maybe we want the grey ones exists in all of the panels.\nfacet_*() facets all layers if the data contains the specified variable, in this case type. In other words, if the layer’s data doesn’t have the variable, it won’t get facetted. Let’s rename it.\n\n\nd_bleached <- d\nnames(d_bleached)[3] <- \"GROUP\"\n\nggplot() +\n  geom_line(data = d_bleached, aes(x, y, group = GROUP), size = 3, colour = \"grey\") +\n  geom_line(data = d_sieved3, aes(x, y, colour = type), size = 3) +\n  facet_wrap(~ type)\n\n\n\n\nYou may notice about one more good thing; the panel for \"a\" disappeared. This is because now d_sieved3 is the only data that contains type and it has only records of \"b\" and \"c\".\nSome spoilers\nThe next version of gghighlight will do the above things almost automatically. All you have to do is just adding gghighlight().\n\n\nlibrary(gghighlight)\n\nggplot(d, aes(x, y, colour = type)) +\n  geom_point(size = 10) +\n  gghighlight(type == \"b\")\n\n\n\n\n\n\nggplot(d, aes(x, y, colour = type)) +\n  geom_line(size = 3) +\n  gghighlight(max(value) >= 10)\n\n\n\n\nStay tuned!\n\n\n\n",
    "preview": "post/2018-06-03-anatomy-of-gghighlight/2018-06-03-anatomy-of-gghighlight_files/figure-html5/gghighlight1-1.png",
    "last_modified": "2021-06-05T23:15:18+09:00",
    "input_file": {}
  },
  {
    "path": "post/2018-02-12-dplyr-S4/",
    "title": "dplyr Doesn't Provide Full Support For S4 (For Now?)",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-02-12",
    "categories": [
      "dplyr"
    ],
    "contents": "\nI’ve seen sooo many (duplicated) issues on this topic were opened on dplyr’s repo and lubridate’s repo.\nFor example, you cannot filter() intervals. Consider the data below:\nlibrary(lubridate)\n#> Loading required package: methods\n#> \n#> Attaching package: 'lubridate'\n#> The following object is masked from 'package:base':\n#> \n#>     date\nlibrary(dplyr, warn.conflicts = FALSE)\n\n# some method of tibble() won't work for interval\nd <- data.frame(\n  i     = interval(ymd(10000101) + years(1:3 * 1000), ymd(10000102) + years(1:3 * 1000)),\n  value = 1:3\n)\n\nd\n#>                                i value\n#> 1 2000-01-01 UTC--2000-01-02 UTC     1\n#> 2 3000-01-01 UTC--3000-01-02 UTC     2\n#> 3 4000-01-01 UTC--4000-01-02 UTC     3\nLet’s select the second row by filter().\nd %>% \n  filter(value == 2L)\n#> Warning in format.data.frame(x, digits = digits, na.encode = FALSE):\n#> corrupt data frame: columns will be truncated or padded with NAs\n#>                                i value\n#> 1 2000-01-01 UTC--2000-01-02 UTC     2\nHmm, can you see something is wrong with the result? In case you don’t notice yet, comparing with the result by base subset() may help:\nsubset(d, value == 2L)\n#>                                i value\n#> 2 3000-01-01 UTC--3000-01-02 UTC     2\nAs you see, the result should be 3000-01-01 UTC--3000-01-02 UTC, whereas filter() returns 2000-01-01 UTC--2000-01-02 UTC. Why? This is related to the structure of interval class. Let’s examine them by str():\nstr(d$i)\n#> Formal class 'Interval' [package \"lubridate\"] with 3 slots\n#>   ..@ .Data: num [1:3] 86400 86400 86400\n#>   ..@ start: POSIXct[1:3], format: \"2000-01-01\" ...\n#>   ..@ tzone: chr \"UTC\"\ninterval objects consist of 3 slots, 2 of which have the same length. This means, to subset this vector, we need to subset .Data and start in the same way. But…\nd %>% \n  filter(value == 2L) %>%\n  str()\n#> 'data.frame':    1 obs. of  2 variables:\n#>  $ i    :Formal class 'Interval' [package \"lubridate\"] with 3 slots\n#>   .. ..@ .Data: num 86400\n#>   .. ..@ start: POSIXct, format: \"2000-01-01\" ...\n#>   .. ..@ tzone: chr \"UTC\"\n#>  $ value: int 2\nYou can notice that it failed to subset start. In contrast, subset() properly subsets the slot as well:\nstr(subset(d, value == 2L))\n#> 'data.frame':    1 obs. of  2 variables:\n#>  $ i    :Formal class 'Interval' [package \"lubridate\"] with 3 slots\n#>   .. ..@ .Data: num 86400\n#>   .. ..@ start: POSIXct, format: \"3000-01-01\"\n#>   .. ..@ tzone: chr \"UTC\"\n#>  $ value: int 2\nThis is because subset() dispatches the proper S4 method for interval, while dplyr fails to handle S4.\nOf course, the maintainers are aware of this issue and seem to plan to address in long-awaited package, vctrs.\nBetter support combining for non-base types · Issue #2432 · tidyverse/dplyr\nSupport nonstandard representations? · Issue #27 · hadley/vctrs\nSo, apparently, the content of this post won’t stay useful over time. But, for now, I feel this temporal “known issue” should be well-known, at least among those who suffers from this issue.\nI hope this post will be outdated soon!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:14:31+09:00",
    "input_file": {}
  },
  {
    "path": "post/2018-02-12-rtweet-auth/",
    "title": "ICYMI: Using rtweet Package Is Super Easy Now!",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2018-02-12",
    "categories": [
      "rtweet"
    ],
    "contents": "\nSince the version 0.6.0 (published on Nov 16, 2017), rtweet package no longer requires the users to create their own apps. Did you notice? I didn’t know this until the author, Michael W. Kearney, kindly answered to my silly question on GitHub. I really appreciate that he is always eager not only to maintain the code but also to communicate with lazy users like me.\nThen, I did a quick poll (sorry, in Japanese) about how well known is the fact. The result is here; 91% of people don’t know about this coolness! So, I am motivated to write a post about how easy rtweet package is now :)\n\n\nRでTwitter APIからデータを取るためにアプリを登録する必要がある、というのは昔の話。今はTwitterアカウントとrtweetパッケージさえあれば準備は不要、と知ってました？\n\n— Hiroaki Yutani (@yutannihilation) 2018年2月9日\n\nAll we need to start rtweet package is…\nliterally this:\n\nNEW: All you need is a Twitter account and rtweet and you’re up and running! (https://github.com/mkearney/rtweet/tree/7e106d6344d2f816c42365401152d60d1c92bd54#usage)\n\nStep1: Create a Twitter account\n(I think you can skip this step; I bet you are Twitter-addicted already, given that you are interested in the data about Twitter, right…?)\nStep2: Install rtweet package\nInstall the package from CRAN as usual:\ninstall.packages(\"rtweet\")\nStep3: Use whatever function of rtweet you like\nIf the function invokes the API calls and it is the first time you run such kind of functions, the browser will be launched to ask for your permission. For example:\ntw <- search_tweets(\"#rstats\", include_rts = FALSE)\nAnd, all you need to do is just click “Authorise app” button on the browser.\n\nNow, the token is aquired and saved in ~/.rtweet_token.rds, which will be automatically used from the next time. That’s all!\nSuper easy!\n(Yet, you need your own app in some cases)\nAs you notice the screenshot above, the default app embeded in rtweet package has read-only permission. So, if you want to do further actions like tweeting and following/unfollowing, you need to create your own app.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:14:45+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-11-07-ggplot-add/",
    "title": "An Example Usage of ggplot_add()",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-11-07",
    "categories": [
      "gghighlight",
      "ggplot2",
      "package"
    ],
    "contents": "\nA generic function ggplot_add() was added to ggplot2 by this PR:\nAllow addition of custom objects by thomasp85 · Pull Request #2309 · tidyverse/ggplot2\nI think creating a custom Geom or Stat and its constructor (geom_*() or stat_*()) is enough for the most of the extension packages of ggplot2, but some people, including me, need this.\nWhy are there no geom_highlight()?\nHere is an example code of my package gghighlight:\ngghighlight_point(d, aes(foo, bar), predicate = bar > 20 & baz == \"A\")\nYou may wonder why this can’t be written like this:\nggplot(d, aes(foo, bar)) +\n  geom_highlight_point(bar > 20 & baz == \"A\")\nLet me explain a bit.\ngeom_*()/stat_*() doesn’t know about the other layers\ngeom_highlight_point(bar > 20 & baz == \"A\") is passed bar > 20 & baz == \"A\" without the data d, with which the expression should be evaluated. It needs d specified in ggplot(...).\nBut, considering the structure of the above code, geom_highlight_point(...) cannot access to the result of ggplot(...) in any usual way:\n`+`(ggplot(...), geom_highlight_point(...))\nIf ggplot2 were designed pipe-friendly, this\n`%>%`(ggplot(...), geom_highlight_point(...))\nwould be evaluated as this, which means geom_highlight_point(...) could take d from ggplot(...)…\ngeom_highlight_point(ggplot(...), ...)\nAnyway, let’s give up here. All I have to do is set this expression as an attribute of a custom Geom and pray that it will be evaluated with the proper data in the phase of building a plot.\nGeom*/Stat* doesn’t know about the original data\nTake a look at the simplest example in the vignette “Extending ggplot2”:\nStatChull <- ggproto(\"StatChull\", Stat,\n  compute_group = function(data, scales) {\n    data[chull(data$x, data$y), , drop = FALSE]\n  },\n\n  required_aes = c(\"x\", \"y\")\n)\nYou may notice that compute_group() expects data has the fixed column x and y. Actually, data is not the original data but the one the mapping is already applied. So, there is no column bar and baz anymore; bar is renamed to y and baz is dropped. Oh no, I cannot evaluate bar > 20 & baz == \"A\" here, too…\nggplot_add()\nLet’s remember this one:\n`+`(ggplot(...), geom_highlight_point(...))\nOnly + (or +.gg) can access to both ggplot(...) and geom_highlight_point(...). This means that, inside +.gg, bar > 20 & baz == \"A\" can be evaluated.\nSo…, should I implement my custom +.gg by myself? No, because I will be able to use ggplot_add()!\nggplot_add() is called in +.gg() via add_ggplot() (very confusing..) and is passed both the original plot and the new object. The current implementation is this:\n\"+.gg\" <- function(e1, e2) {\n  # Get the name of what was passed in as e2, and pass along so that it\n  # can be displayed in error messages\n  e2name <- deparse(substitute(e2))\n\n  if      (is.theme(e1))  add_theme(e1, e2, e2name)\n  else if (is.ggplot(e1)) add_ggplot(e1, e2, e2name)\n  else if (is.ggproto(e1)) {\n    stop(\"Cannot add ggproto objects together.\",\n         \" Did you forget to add this object to a ggplot object?\",\n         call. = FALSE)\n  }\n}\n(https://github.com/tidyverse/ggplot2/blob/7d0549a03e5ea08c27c768e88d5717f18cb4a5ce/R/plot-construction.r#L40-L52)\nadd_ggplot <- function(p, object, objectname) {\n  if (is.null(object)) return(p)\n\n  p <- plot_clone(p)\n  p <- ggplot_add(object, p, objectname)\n  set_last_plot(p)\n  p\n}\n(https://github.com/tidyverse/ggplot2/blob/7d0549a03e5ea08c27c768e88d5717f18cb4a5ce/R/plot-construction.r#L59-L66)\nBy using this, I can implement the proof-of-concept version of geom_highlight_point() as bellow:\ngeom_highlight_point <- function(expr) {\n  structure(list(expr = rlang::enquo(expr)), class = \"highlight\")\n}\n\nggplot_add.highlight <- function(object, plot, object_name) {\n  new_data <- dplyr::filter(plot$data, !! object$expr)\n  new_layer <- geom_point(data = new_data,\n                          mapping = plot$mapping,\n                          colour = alpha(\"red\", 0.5),\n                          size = 5)\n  plot$layers <- append(plot$layers, new_layer)\n  plot\n}\nlibrary(ggplot2)\n\nd <- data.frame(foo = 11:30, bar = 11:30, baz = rep(c(\"A\", \"B\", \"C\"), length.out = 20),\n                stringsAsFactors = FALSE)\n\nggplot(d, aes(foo, bar)) +\n  geom_highlight_point(bar > 20 & baz == \"A\") +\n  geom_point()  # for comparison\nplot of chunk use-geom-highlight-pocI’m not sure if this is the intended usage of ggplot_add(), but this seems very nice. Looking forward to the next release of ggplot2!\n\n\n\n",
    "preview": "https://yutani.rbind.io/post/2017-11-07-ggplot-add/2017-11-07-ggplot-add_files/figure-html/use-geom-highlight-poc-1.png",
    "last_modified": "2021-06-05T23:14:15+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-10-26-post-to-medium/",
    "title": "Publish R Markdown to Medium via An RStudio Addin",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-10-26",
    "categories": [
      "Medium",
      "Web API"
    ],
    "contents": "\nI created an experimental package to work with Medium API.\nmediumr: https://github.com/yutannihilation/mediumr/\nmediumr allows you to knit and post R Markdown to Medium.\nInstallation\nYou can install mediumr from github with:\ndevtools::install_github(\"yutannihilation/mediumr\")\nAuthentication\nMedium API requires a self-issued API token. (While they provide OAuth method, it’s hard for R users to use it since localhost is not allowed to specify in the callback URL.) Please issue a token in “Integration tokens” section of settings and set it as a environmental variable MEDIUM_API_TOKEN. If you use .Renviron, add this line:\nMEDIUM_API_TOKEN='<your api token here>'\nUsage\nThe usage is quite simple. Focus on the Rmd file that you want to publish and choose “Post to Medium” from Addins menu (Or, you can execute mediumr::medium_create_post_from_Rmd(\"path/to/file.Rmd\") in your console.):\n\nThe addin knits the Rmd and shows the preview dialog. If it looks ok, click “Publish”:\n\nAfter successfully uploading the content to Medium, the addin launches a web browser and jumps to the post:\n\nOther usages\nmediumr also provides simple bindings for Medium API. Please, read the “Usage” section of the README.\nContribution\nIf you find any problems, please let me know on GitHub, Twitter, or comment here!\n\n\n\n",
    "preview": "https://yutani.rbind.io/post/2017-10-26-post-to-medium/images/2017-10-26-screenshot_medium.png",
    "last_modified": "2021-06-05T23:14:00+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-10-25-blogdown-custom/",
    "title": "How Not To Knit All Rmd Files With Blogdown",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-10-25",
    "categories": [
      "blogdown"
    ],
    "contents": "\nBlogdown is a cool package. But, if I complain about one thing, it will be the default behaviour of build_site(), which every blogdownners should execute everytime they wants to publish a new article.\nAs stated in the documentation, build_site() will\n\nCompile all Rmd files and build the site through Hugo.\n(?build_site)\n\nCompiling all Rmd files is “safe” in the sense that we can notice if some Rmd becomes impossible to compile due to some breaking changes of some package. But, it may be time-consuming and can be a problem for those who have a lot of .Rmd files.\nThough I don’t find the best practice yet, I noticed using a custom build script (R/build.R) is useful for this purpose. (Note that I’ve aquired many tips from Yihui’s repo. Thanks Yihui for being great as usual!)\nSet blogdown.method option to \"custom\"\nFirst, stop build_site() compiling all Rmd files by specifying method = \"custom\".\n\nmethod = \"custom\" means it is entirely up to this R script how a website is rendered.\n(?build_site)\n\nWhile this option can be passed as an argument of build_site(), it can also be set as a global option blogdown.method. Put this line in .Rprofile in the home directory or the top directory of the project for your blog.\noptions(blogdown.method = 'custom')\nYou may also need to source the default ~/.Rprofile.\nif (file.exists('~/.Rprofile')) sys.source('~/.Rprofile', envir = environment())\nWrite R/build.R\nNext, write a custom script and save it as R/build.R. If R/build.R exists, blogdown executes it:\n\nFor all rendering methods, a custom R script ‘R/build.R’ will be executed if you have provided it under the root directory of the website\n(?build_site)\n\nThis occurs regardless of which method we choose. By using R/build.R, you can add some preprocessing phase when method = \"html\", or you can replace the whole process of building the website when method = \"custom\".\nHere is my R/build.R (Some explanations follow). You can find other scripts by searching on GitHub.\n# catch \"local\" arg passed from blogdown::build_site()\nlocal <- commandArgs(TRUE)[1] == \"TRUE\"\n\n# set common options ofr knitr\nknitr::opts_knit$set(\n  base.dir = normalizePath(\"static/\", mustWork = TRUE),\n  base.url = \"/\"\n)\n\nknitr::opts_chunk$set(\n  cache.path = normalizePath(\"cache/\", mustWork = TRUE),\n  collapse = TRUE,\n  comment  = \"#>\"\n)\n\n# list up Rmd files\nRmd_files <- list.files(\"content\", \"\\\\.Rmd$\", recursive = TRUE, full.names = TRUE)\n\n# list up md files\nmd_files  <- sub(\"\\\\.Rmd$\", \".md\", Rmd_files)\nnames(md_files) <- Rmd_files\n\n# knit it when:\n#   1) the correspondent md file does not exist yet\n#   2) the Rmd file was updated after the last time md file had been generated \nneeds_knitted <- !file.exists(md_files) | utils::file_test(\"-ot\", md_files, Rmd_files)\n\nmessage(\"skip: \\n    \", paste(Rmd_files[!needs_knitted], collapse = \"\\n    \"))\n\nfor (rmd in Rmd_files[needs_knitted]) {\n  base_name <- tools::file_path_sans_ext(basename(rmd))\n  knitr::opts_chunk$set(\n    fig.path = glue::glue(\"post/{base_name}_files/figure-html/\")\n  )\n  \n  set.seed(1984)\n  knitr::knit(input = rmd, output = md_files[rmd], encoding = \"UTF-8\")\n}\n\nblogdown::hugo_build(local = local)\n(I guess this script is incomplete to handle htmlwidgets correctly. I will improve this someday…)\nSet paths correctly\nIf we leave the protection of blogdown, we have to face with the complexity of paths by ourselves.\n\nR plots under content/*/foo_files/figure-html/ are copied to static/*/foo_files/figure-html/, and the paths in HTML tags like <img src=\"foo_files/figure-html/bar.png\" /> are substituted by /*/foo_files/figure-html/bar.png. Note the leading slash indicates the root directory of the published website, and the substitution works because Hugo will copy */foo_files/figure-html/ from static/ to public/.\n(https://bookdown.org/yihui/blogdown/dep-path.html)\n\nFortunately, setting these seems enough in my case (yes, I also cheat here by exporing Yihui’s repo):\nbase.url: /\nbase.path: static/\nfig.path: post/{base_name}_files/figure-html/\ncache.path: cache/ (since I changed base.path, cache/ needs to be translated as an absolute path)\nAs we need to inject these chunk and knit options, we have to use knitr::knitr() directly instead of rmarkdown::render(). But, since blogdown book says this threatening words, I may not see another day… Take care of life.\n\nYou should not modify the knitr chunk option fig.path or cache.path unless the above process is completely clear to you, and you want to handle dependencies by yourself.\n(https://bookdown.org/yihui/blogdown/dep-path.html)\n\nGenerate markdown files, not HTML files\nThis is another reason why you don’t need to use rmarkdown package. Let knitr generate markdown and let Hugo generate HTML from markdown. As this job is up to Hugo in Netlify, public/ directory is not needed anymore. Add it to .gitignore.\npublic\nSkip files already knitted\nIf the .md file is newer than the .Rmd file, it is probally unnecessary to compile. utils::file_test() can tell this.\n# knit it when:\n#   1) the correspondent md file does not exist yet\n#   2) the Rmd file was updated after the last time md file had been generated \nneeds_knitted <- !file.exists(md_files) | utils::file_test(\"-ot\", md_files, Rmd_files)\nFeedbacks are welcome!\nIt seems everything works fine in my repo, I’m not sure whether I’m doing things right or not. Please let me know if you find some problem or better way!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:13:25+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-10-25-dplyr-select/",
    "title": "dplyr::select() Accepts Characters Since Version 0.7.0",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-10-25",
    "categories": [
      "dplyr",
      "tidyeval"
    ],
    "contents": "\nSome of my friends didn’t aware that dplyr now accepts characters. Did you?\nFor example, this expression\nselect(iris, Sepal.Length, Petal.Length)\ncan be also written in this way:\nselect(iris, \"Sepal.Length\", \"Petal.Length\")\nor in this way:\nselect(iris, c(\"Sepal.Length\", \"Petal.Length\"))\nFor the semantics of select(), you can find a good explanation in the vignette.\nTidyeval?\nYou may want to write some code that selects columns programmatically using variables.\nx <- c(\"col1\", \"col2\")\nselect(some_data, x)\nBut, be fareful, x can be ambiguous. If some_data has a column named x, it selects the column x instead of col1 and col2, the content of the variable x.\nTo avoid these troubles, you should explicitly unquote x by !! or !!! (both are ok in this case).\nx <- c(\"col1\", \"col2\")\nselect(some_data, !! x)\nrlang::expr() can show how the expression is unquoted.\nx <- c(\"col1\", \"col2\")\n\nrlang::expr(select(some_data, !! x))\n#> select(some_data, c(\"col1\", \"col2\"))\n\nrlang::expr(select(some_data, !!! x))\n#> select(some_data, \"col1\", \"col2\")\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:13:40+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-10-21-rd-diff/",
    "title": "Confession: It's Me Who Committed the Change to Suppress .Rd Diffs On GitHub",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-10-21",
    "categories": [
      "GitHub"
    ],
    "contents": "\nYou may notice that diffs of .Rd files are suppressed by default on GitHub since some time.\n\nDo you wonder who did this? It’s me, yay! This is my pull request:\nIgnore roxygen2 generated files by yutannihilation · Pull Request #3373 · github/linguist\nThough I thought I’ve done the right thing at that time, now I’m afraid this change may be bad for some cases…\nAfter the relese of roxygen2 6.0.0, the game has changed a bit. We can use Markdown to write package document now.\nroxygen2 6.0.0 | RStudio Blog\nThe feature itself is so cool (I use it often), but sometimes it behaves against our expectations:\nhttps://github.com/tidyverse/dplyr/pull/2801\nhttps://github.com/tidyverse/purrr/pull/361\nShould we stop suppressing the .Rd diffs to review with the eyes? If you think so, please send the revert pull request to github/linguist. But I hope my effort improved the experience of R development on GitHub.\n\n\n\n",
    "preview": "https://yutani.rbind.io/post/2017-10-21-rd-diff/images/2017-10-21-diff-suppressed.png",
    "last_modified": "2021-06-05T23:13:09+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-10-18-circleci/",
    "title": "Use CircleCI for R Projects",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-10-18",
    "categories": [
      "testthat",
      "CircleCI"
    ],
    "contents": "\nWhy CircleCI? Yes, I know using Travis CI is this easy, thanks to devtools package:\ndevtools::use_travis()\nTravis CI is OK most of the time. Still, CircleCI has some advantages:\narbitrary Docker images\ncool test summaries\nArbitrary Docker images\nCompared to Travis CI, CircleCI allows the users to use any docker images. For example, my WIP package which provides DBI-compatible interface to Redash uses these images:\n     docker:\n       - image: rocker/tidyverse:latest\n\n       - image: redis:3.0-alpine\n\n       - image: postgres:9.5.6-alpine\n\n       - image: redash/redash:latest\n         command: [server]\n         environment:\n           PYTHONUNBUFFERED: 0\n           REDASH_LOG_LEVEL: \"INFO\"\n           REDASH_REDIS_URL: \"redis://localhost:6379/0\"\n           REDASH_DATABASE_URL: \"postgresql://postgres@localhost/postgres\"\n           REDASH_COOKIE_SECRET: veryverysecret\n           REDASH_WEB_WORKERS: 4\n\n       - image: redash/redash:latest\n         command: [scheduler]\n         environment:\n           PYTHONUNBUFFERED: 0\n           REDASH_LOG_LEVEL: \"INFO\"\n           REDASH_REDIS_URL: \"redis://localhost:6379/0\"\n           REDASH_DATABASE_URL: \"postgresql://postgres@localhost/postgres\"\n           QUEUES: \"queries,scheduled_queries,celery\"\n           WORKERS_COUNT: 2\n(https://github.com/yutannihilation/Redashr/blob/71b525872c0c7b7f7d7cf8f3eaee8ad4d869b89e/.circleci/config.yml#L82-L110)\nWhile Redis and PostgresSQL services are available in Travis CI, users have to compile Redash, which takes some time. It tends to fail again and again due to lack of commands or library needed for compiling. Sigh.\nThough Travis can cache the setup once it succeeds, it is good if we can save time to setup testing environment by using existing Docker images.\nTest summaries\nCircleCI displays the test summary in this pretty way:\n (https://circleci.com/gh/yutannihilation/testthatJunitRporterTest/25)\nThis is cool as I don’t need to dig raw outputs anymore. This is possible by JunitReporter, which will be introduced the next version (v2.0.0?) of testthat package.\nAll I had to do was two steps.\nFirst, pass JunitReporter instance with the location of the result XML file to test_check() in tests/testthat.R:\nlibrary(testthat)\nlibrary(mypackage)\n\ntest_check(\"mypackage\",\n           reporter = JunitReporter$new(file = \"junit_result.xml\"))\nSecond, specify store_test_result on config.yml for CircleCI:\n    - store_test_results:\n        path: /path/to/tests/\n        when: always\nSo simple!\nSample YAML file\nThe bellow is the CircleCI setting I tried to do roughly the same as what Travis CI does. If you have some suggestions, please let me know!\ndefaults: &steps\n  steps:\n    - checkout\n\n    ## setup -------------------------------\n\n    - run:\n        name: Set environmental variables\n        command: |\n          Rscript --vanilla \\\n            -e 'dsc <- read.dcf(\"DESCRIPTION\")' \\\n            -e 'cat(sprintf(\"export PKG_TARBALL=%s_%s.tar.gz\\n\", dsc[,\"Package\"], dsc[,\"Version\"]))' \\\n            -e 'cat(sprintf(\"export RCHECK_DIR=%s.Rcheck\\n\", dsc[,\"Package\"]))' \\\n            >> ${BASH_ENV}\n\n    ## install dependencies ------------------\n\n    - run:\n        name: Install devtools and dependencies\n        command: |\n          Rscript \\\n            -e 'if (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")' \\\n            -e 'devtools::install_deps(dependencies = TRUE)'\n\n    ## build and test -----------------\n\n    - run:\n        name: Build package\n        command: R CMD build .\n\n    - run:\n        name: Check package\n        command: R CMD check \"${PKG_TARBALL}\" --as-cran --no-manual\n    - run:\n        name: Check failures\n        command: |\n          Rscript -e \"message(devtools::check_failures(path = '${RCHECK_DIR}'))\"\n          # warnings are errors\n          # - run: if grep -q -R \"WARNING\" \"${RCHECK_DIR}/00check.log\"; then exit 1; fi\n\n    ## store artifacts -----------------\n\n    - run:\n        command: mv ${RCHECK_DIR} /tmp/Rcheck\n        when: always\n    - store_test_results:\n        path: /tmp/Rcheck/tests/\n        when: always\n    - store_artifacts:\n        path: /tmp/Rcheck\n        when: always\n\nversion: 2\njobs:\n  \"r-release\":\n     docker:\n       - image: rocker/tidyverse:latest\n     <<: *steps\n\n  \"r-devel\":\n     docker:\n       - image: rocker/tidyverse:devel\n     <<: *steps\n\nworkflows:\n  version: 2\n  build_and_test:\n    jobs:\n      - \"r-release\"\n      - \"r-devel\"\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-05T23:12:56+09:00",
    "input_file": {}
  },
  {
    "path": "post/2017-10-06-gghighlight/",
    "title": "Introduction to gghighlight: Highlight ggplot's Lines and Points with Predicates",
    "description": {},
    "author": [
      {
        "name": "Hiroaki Yutani",
        "url": {}
      }
    ],
    "date": "2017-10-06",
    "categories": [
      "gghighlight",
      "ggplot2",
      "package"
    ],
    "contents": "\n(Update: The functions introduced here is deprecated now. Please use gghighlight(), which is far nicer one)\nSuppose we have a data that has too many series like this:\nset.seed(2)\nd <- purrr::map_dfr(\n  letters,\n  ~ data.frame(idx = 1:400,\n               value = cumsum(runif(400, -1, 1)),\n               type = .,\n               stringsAsFactors = FALSE))\nFor such data, it is almost impossible to identify a series by its colour as their differences are so subtle.\nlibrary(ggplot2)\n\nggplot(d) +\n  geom_line(aes(idx, value, colour = type))\nplot of chunk plotHighlight lines with ggplot2 + dplyr\nSo, I am motivated to filter data and map colour only on that, using dplyr:\nlibrary(dplyr, warn.conflicts = FALSE)\n\nd_filtered <- d %>%\n  group_by(type) %>% \n  filter(max(value) > 20) %>%\n  ungroup()\n\nggplot() +\n  # draw the original data series with grey\n  geom_line(aes(idx, value, group = type), data = d, colour = alpha(\"grey\", 0.7)) +\n  # colourise only the filtered data\n  geom_line(aes(idx, value, colour = type), data = d_filtered)\nplot of chunk dplyrBut, what if I want to change the threshold in predicate (max(.data$value) > 20) and highlight other series as well? It’s a bit tiresome to type all the code above again every time I replace 20 with some other value.\nHighlight lines with gghighlight\ngghighlight package provides two functions to do this job. You can install this via CRAN (or GitHub)\ninstall.packages(\"gghighlight\")\ngghighlight_line() is the one for lines. The code equivalent to above (and more) can be this few lines:\nlibrary(gghighlight)\n\ngghighlight_line(d, aes(idx, value, colour = type), predicate = max(value) > 20)\nplot of chunk gghighlight-line-basicAs gghighlight_*() returns a ggplot object, it is fully customizable just as we usually do with ggplot2 like custom themes and facetting.\nlibrary(ggplot2)\n\ngghighlight_line(d, aes(idx, value, colour = type), max(value) > 20) +\n  theme_minimal()\nplot of chunk gghighlight-themegghighlight_line(d, aes(idx, value, colour = type), max(value) > 20) +\n  facet_wrap(~ type)\nplot of chunk gghighlight-facetBy default, gghighlight_line() calculates predicate per group, more precisely, dplyr::group_by() + dplyr::summarise(). So if the predicate expression returns multiple values per group, it ends up with an error like this:\ngghighlight_line(d, aes(idx, value, colour = type), value > 20)\n#> Error in summarise_impl(.data, dots): Column `predicate..........` must be length 1 (a summary value), not 400\nHighlight points with gghighlight\ngghighlight_point() highlight points. While gghighlight_line() evaluates predicate by grouped calculation (dplyr::group_by()), by default, this function evaluates it by ungrouped calculation.\nset.seed(19)\nd2 <- sample_n(d, 100L)\n\ngghighlight_point(d2, aes(idx, value), value > 10)\n#> Warning in gghighlight_point(d2, aes(idx, value), value > 10): Using type\n#> as label for now, but please provide the label_key explicity!\nplot of chunk gghighlight-pointAs the job is done without grouping, it’s better to provide gghighlight_point() a proper key for label, though it tries to choose proper one automatically. Specifying label_key = type will stop the warning above:\ngghighlight_point(d2, aes(idx, value), value > 10, label_key = type)\nYou can control whether to do things with grouping by use_group_by argument. If this set to TRUE, gghighlight_point() evaluate predicate by grouped calculation.\ngghighlight_point(d2, aes(idx, value, colour = type), max(value) > 15, label_key = type,\n                  use_group_by = TRUE)\nplot of chunk gghighlight-point-groupedNon-logical predicate\n(Does “non-logical predicate” make sense…? Due to my poor English skill, I couldn’t come up with a good term other than this. Any suggestions are wellcome.)\nBy the way, to construct a predicate expression like bellow, we need to determine a threshold (in this example, 20). But it is difficult to choose a nice one before we draw plots. This is a chicken or the egg situation.\nmax(value) > 20\nSo, gghiglight_*() allows predicates that will be evaluated into non-logical values. The result value will be used to sort data, and the top max_highlight data points/series will be highlighted. For example:\ngghighlight_line(d, aes(idx, value, colour = type), predicate = max(value),\n                 max_highlight = 6)\nplot of chunk non-logical-predicateCaveats\nSeems cool? gghighlight is good to explore data by changing a threshlold little by little. But, the internals are not so efficient, as it does almost the same calculation everytime you execute gghighlight_*(), which may get slower when it works with larger data. Consider doing this by using vanilla dplyr to filter data.\nSummary\ngghighlight package is a tool to highlight charactaristic data series among too many ones. Please try!\nBug reports or feature requests are welcome! -> https://github.com/yutannihilation/gghighlight/issues\n\n\n\n",
    "preview": "https://yutani.rbind.io/post/2017-10-06-gghighlight/2017-10-06-gghighlight_files/figure-html/non-logical-predicate-1.png",
    "last_modified": "2021-06-05T23:12:39+09:00",
    "input_file": {}
  }
]
